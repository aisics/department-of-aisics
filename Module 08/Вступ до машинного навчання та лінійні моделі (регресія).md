**Лекція 8: Вступ до машинного навчання та лінійні моделі (регресія)**

**Мета лекції:** Дати загальне уявлення про машинне навчання (ML), його основні парадигми та процес розробки ML-моделей. Детально розглянути один з найпростіших та найфундаментальніших алгоритмів навчання з учителем – лінійну регресію. Пояснити, як математичні концепції (лінійна алгебра, математичний аналіз), вивчені раніше, застосовуються для побудови та навчання цієї моделі, зокрема за допомогою методу градієнтного спуску.

---

Доброго дня! На попередніх лекціях ми заклали математичний фундамент, розглянувши основи лінійної алгебри, математичного аналізу та теорії ймовірностей. Сьогодні ми починаємо бачити, як ці інструменти оживають і застосовуються на практиці в захопливій сфері **машинного навчання (Machine Learning - ML)**.

Що таке машинне навчання? Якщо коротко, це галузь штучного інтелекту, яка дає комп'ютерам здатність **навчатися з даних** без того, щоб бути явно запрограмованими на кожну конкретну задачу. Замість того, щоб писати детальні інструкції, ми створюємо алгоритми, які можуть виявляти закономірності в даних і використовувати їх для прогнозування або прийняття рішень.

Сьогодні ми:

1.  Розглянемо **основні парадигми** машинного навчання.
2.  Ознайомимось із типовим **процесом розробки** ML-моделі.
3.  Заглибимось у **лінійну регресію** – простий, але потужний інструмент для прогнозування числових значень.
4.  З'ясуємо, як **градієнтний спуск** допомагає "навчити" модель лінійної регресії.

---

**Основні парадигми машинного навчання**

Існує три основні категорії алгоритмів машинного навчання, які відрізняються типом даних, що використовуються, та завданнями, які вони вирішують:

1.  **Навчання з учителем (Supervised Learning):**
    * **Ідея:** Модель навчається на **розмічених даних**, де для кожного вхідного прикладу (набору ознак) відома правильна відповідь (мітка або цільове значення). Алгоритм вчиться знаходити відповідність між входами та виходами.
    * *Аналогія:* Учень навчається за підручником з відповідями, де вчитель показує правильні рішення.
    * **Типи задач:**
        * **Регресія (Regression):** Прогнозування неперервного числового значення.
            * *Приклади:* Прогноз ціни будинку на основі його площі, кількості кімнат тощо; прогноз температури повітря; прогноз обсягу продажів. *Сьогодні ми детально розглянемо лінійну регресію.*
        * **Класифікація (Classification):** Прогнозування категоріальної мітки (класу).
            * *Приклади:* Визначення, чи є лист спамом (класи: "спам", "не спам"); розпізнавання рукописних цифр (класи: 0, 1, ..., 9); медична діагностика (класи: "хворий", "здоровий").

2.  **Навчання без учителя (Unsupervised Learning):**
    * **Ідея:** Модель навчається на **нерозмічених даних**, намагаючись самостійно знайти приховані структури, закономірності або взаємозв'язки в даних.
    * *Аналогія:* Дослідник аналізує великий масив даних, намагаючись знайти цікаві групи чи тенденції без попередніх підказок.
    * **Типи задач:**
        * **Кластеризація (Clustering):** Групування схожих об'єктів даних разом.
            * *Приклади:* Сегментація клієнтів за купівельною поведінкою; групування новин за темами.
        * **Зменшення розмірності (Dimensionality Reduction):** Скорочення кількості ознак (змінних) у даних зі збереженням найважливішої інформації.
            * *Приклади:* Стиснення даних; візуалізація багатовимірних даних; метод головних компонент (PCA), який ми згадували у зв'язку з власними векторами.
        * **Пошук асоціативних правил (Association Rule Learning):** Виявлення правил типу "якщо ..., то ...".
            * *Приклади:* Аналіз ринкового кошика ("клієнти, що купують пиво, часто купують і чипси").

3.  **Навчання з підкріпленням (Reinforcement Learning - RL):**
    * **Ідея:** Модель (агент) навчається взаємодіяти із **середовищем** і приймати послідовні **рішення (дії)** так, щоб максимізувати певну **винагороду** в довгостроковій перспективі. Навчання відбувається методом спроб і помилок.
    * *Аналогія:* Дресирування тварини за допомогою команд та винагород/покарань.
    * **Ключові компоненти:** Агент, Середовище, Стан, Дія, Винагорода.
    * *Приклади:* Навчання комп'ютерних програм грі в шахи чи Го (AlphaGo); керування роботами; оптимізація систем рекомендацій; автономне водіння.

Ці парадигми не завжди чітко розділені, існують і гібридні підходи (наприклад, напівконтрольоване навчання).

---

**Процес розробки моделі машинного навчання**

Створення ефективної ML-моделі – це ітеративний процес, який зазвичай включає наступні кроки:

1.  **Розуміння задачі та постановка мети:** Що саме ми хочемо досягти? Яку бізнес-проблему вирішуємо? Які метрики успіху?
2.  **Збір даних:** Знаходження та збір даних, релевантних для поставленої задачі.
3.  **Підготовка та попередня обробка даних (Data Preprocessing):** **Дуже важливий етап!**
    * Очищення даних (обробка пропущених значень, викидів).
    * Трансформація даних (масштабування ознак, кодування категоріальних змінних).
    * Розділення даних на навчальну (training), валідаційну (validation) та тестову (test) вибірки. Навчальна – для "навчання" моделі, валідаційна – для налаштування параметрів моделі, тестова – для фінальної, незалежної оцінки якості навченої моделі.
4.  **Вибір моделі:** Підбір одного або декількох алгоритмів ML, які підходять для вирішення задачі (регресія, класифікація, лінійна модель, дерево рішень, нейромережа тощо). Починати варто з простіших моделей.
5.  **Навчання моделі (Training):** Використання навчальної вибірки для налаштування внутрішніх параметрів моделі (наприклад, ваг) шляхом мінімізації функції втрат.
6.  **Оцінка моделі (Evaluation):** Перевірка якості навченої моделі на валідаційній (або тестовій) вибірці за допомогою обраних метрик (наприклад, середня квадратична помилка для регресії, точність для класифікації).
7.  **Налаштування гіперпараметрів та покращення моделі (Tuning):** Зміна налаштувань самого алгоритму (не тих, що вивчаються з даних, а тих, що задаються до навчання, наприклад, швидкість навчання) або вибір іншої моделі для покращення результатів. Повернення до кроку 5.
8.  **Розгортання моделі (Deployment):** Впровадження навченої моделі в реальну систему для використання.
9.  **Моніторинг та підтримка:** Спостереження за роботою моделі в реальних умовах та її періодичне оновлення або перенавчання при необхідності.

---

**Лінійна регресія (Linear Regression)**

Це один з найпростіших і найпоширеніших алгоритмів **навчання з учителем** для задач **регресії**.

* **Мета:** Знайти лінійну залежність між однією чи кількома незалежними змінними (ознаками, $x$) та залежною неперервною змінною (цільовим значенням, $y$).
* **Приклад:** Прогнозування ціни будинку ($y$) на основі його площі ($x$). Ми припускаємо, що існує приблизно лінійна залежність: чим більша площа, тим вища ціна.

* **Гіпотеза ($h_\theta(x)$):** Це математична функція, яку використовує наша модель для прогнозування. У лінійній регресії це рівняння прямої (для однієї ознаки) або гіперплощини (для багатьох ознак).
    * **Проста лінійна регресія (одна ознака $x$):**
        $h_\theta(x) = \theta_0 + \theta_1 x$
        Тут $\theta_0$ (theta-нуль) – це точка перетину з віссю Y (зміщення, bias), а $\theta_1$ (theta-один) – кутовий коефіцієнт прямої (вага ознаки, weight).
    * **Множинна лінійна регресія (n ознак $x_1, ..., x_n$):**
        $h_\theta(x) = \theta_0 + \theta_1 x_1 + \theta_2 x_2 + ... + \theta_n x_n$
    * **Векторний запис:** Якщо додати фіктивну ознаку $x_0 = 1$, то гіпотезу можна записати компактно за допомогою скалярного добутку векторів (згадуємо лінійну алгебру!):
        $h_\theta(x) = \theta^T x$, де $\theta = (\theta_0, \theta_1, ..., \theta_n)^T$ – вектор параметрів, $x = (x_0, x_1, ..., x_n)^T$ – вектор ознак (з $x_0=1$).

* **Параметри ($\theta$):** Це значення $\theta_0, \theta_1, ..., \theta_n$, які модель має **вивчити** з навчальних даних. Наше завдання – знайти "найкращі" значення параметрів.

* **Функція втрат / Функція вартості (Loss / Cost Function, $J(\theta)$):** Це функція, яка вимірює, наскільки "погано" працює наша модель з поточними параметрами $\theta$. Вона показує середню помилку між прогнозами моделі $h_\theta(x^{(i)})$ та реальними значеннями $y^{(i)}$ на навчальній вибірці з $m$ прикладів. Наша мета – **мінімізувати** цю функцію.
    * **Середня квадратична помилка (Mean Squared Error - MSE):** Найпоширеніша функція втрат для регресії.
        $J(\theta) = \frac{1}{2m} \sum_{i=1}^{m} (h_\theta(x^{(i)}) - y^{(i)})^2$
        * Ми беремо різницю між прогнозом і реальним значенням для кожного прикладу $(h_\theta(x^{(i)}) - y^{(i)})$.
        * Підносимо її до квадрату, щоб помилки не компенсували одна одну і щоб більші помилки карались сильніше.
        * Сумуємо квадрати помилок по всіх $m$ навчальних прикладах.
        * Ділимо на $m$ (або $2m$ для зручності взяття похідної), щоб отримати середню помилку.

* **Метод найменших квадратів (Method of Least Squares):** Принцип, що лежить в основі пошуку найкращих параметрів $\theta$ для лінійної регресії при використанні MSE – це знайти таку лінію (або гіперплощину), яка мінімізує суму квадратів вертикальних відстаней від кожної точки даних до цієї лінії. Існує аналітичний розв'язок (нормальне рівняння), але для великих даних частіше використовують ітераційні методи.

---

**Градієнтний спуск (Gradient Descent)**

Як нам знайти ті значення параметрів $\theta$, які мінімізують функцію втрат $J(\theta)$? Тут нам на допомогу приходить **градієнтний спуск**, який ми вже згадували при обговоренні оптимізації в математичному аналізі.

* **Ідея:** Це ітеративний алгоритм оптимізації. Ми починаємо з якихось початкових значень $\theta$ (наприклад, нульових) і на кожному кроці трохи коригуємо їх так, щоб рухатись у напрямку **найшвидшого зменшення** функції втрат $J(\theta)$.
* **Аналогія:** Уявіть, що ви стоїте на схилі гори в тумані ($J(\theta)$ – висота) і хочете спуститися вниз (знайти мінімум). Ви дивитесь навколо себе, визначаєте напрямок найкрутішого схилу вниз (протилежний до градієнта $\nabla J(\theta)$) і робите невеликий крок у цьому напрямку. Повторюєте це знову і знову.

* **Алгоритм:**
    1.  Ініціалізувати параметри $\theta$ (наприклад, нулями або малими випадковими значеннями).
    2.  Повторювати до збіжності:
        a.  Обчислити градієнт функції втрат $\nabla J(\theta)$, тобто вектор частинних похідних $\frac{\partial J(\theta)}{\partial \theta_j}$ для кожного параметра $\theta_j$.
        b.  Оновити кожен параметр $\theta_j$ одночасно за правилом:
            $\theta_j := \theta_j - \alpha \frac{\partial J(\theta)}{\partial \theta_j}$
* **Компоненти правила оновлення:**
    * $\theta_j$: Поточне значення параметра, який ми оновлюємо.
    * $\alpha$: **Швидкість навчання (Learning Rate)** – мале додатне число, яке контролює розмір кроку. Якщо $\alpha$ занадто мале, навчання буде повільним. Якщо занадто велике – можемо "перестрибнути" мінімум або навіть розійтися. Вибір $\alpha$ є важливим гіперпараметром.
    * $\frac{\partial J(\theta)}{\partial \theta_j}$: **Частинна похідна** функції втрат по параметру $\theta_j$. Вона показує, як зміниться $J(\theta)$, якщо трохи змінити $\theta_j$. Градієнт вказує напрямок найшвидшого *зростання* $J(\theta)$, тому ми віднімаємо його (рухаємось у протилежному напрямку).
    * Для лінійної регресії з MSE, ця похідна дорівнює: $\frac{\partial J(\theta)}{\partial \theta_j} = \frac{1}{m} \sum_{i=1}^{m} (h_\theta(x^{(i)}) - y^{(i)}) x_j^{(i)}$. (Де $x_j^{(i)}$ – значення j-ої ознаки для i-го прикладу).

* **Збіжність:** Алгоритм зупиняється, коли параметри $\theta$ майже перестають змінюватись, або коли функція втрат $J(\theta)$ досягає певного низького значення, або після фіксованої кількості ітерацій.

Градієнтний спуск – це робоча конячка оптимізації у машинному навчанні, яка використовується для навчання не лише лінійної регресії, а й багатьох інших, значно складніших моделей, включаючи нейронні мережі.

---

**Підсумки**

* Машинне навчання дозволяє комп'ютерам навчатися з даних. Основні парадигми: **навчання з учителем** (регресія, класифікація), **без учителя** (кластеризація, зменшення розмірності) та **з підкріпленням**.
* Розробка ML-моделі – це ітеративний процес, що включає збір та обробку даних, вибір моделі, навчання, оцінку та налаштування.
* **Лінійна регресія** – це базова модель навчання з учителем для прогнозування числових значень, що використовує лінійну гіпотезу ($h_\theta(x) = \theta^T x$).
* Модель навчається шляхом знаходження параметрів $\theta$, які мінімізують **функцію втрат** (часто **MSE**), що вимірює помилку прогнозів.
* **Градієнтний спуск** – це ітеративний алгоритм оптимізації, який знаходить мінімум функції втрат, рухаючись кроками у напрямку, протилежному до градієнта.

Ми побачили, як лінійна алгебра (вектори, матриці), математичний аналіз (похідні, градієнт) та теорія ймовірностей (функція втрат як міра очікуваної помилки) об'єднуються для створення та навчання навіть найпростішої моделі машинного навчання. Це лише початок шляху!

**Наступні кроки**

* Подумайте, які ще задачі з вашого досвіду можна було б вирішити за допомогою лінійної регресії.
* На наступній лекції ми розглянемо іншу фундаментальну задачу навчання з учителем – класифікацію, і познайомимося з моделлю логістичної регресії.

---

Дякую за увагу! Не забуваємо про вподобайку, поширення та чесний відгук чи запитання в коментарях, до зустрічі!