**Лекція 9: Лінійні моделі (класифікація) та оцінка моделей**

**Мета лекції:** Перейти від задач регресії до задач класифікації. Розглянути логістичну регресію як основний лінійний метод для бінарної та мультикласової класифікації. Ознайомитися з ключовими метриками для оцінки якості моделей класифікації. Обговорити поширені проблеми перенавчання та недонавчання, а також важливість правильного розділення даних.

---

Доброго дня! Минулого разу ми детально розглянули лінійну регресію – модель, що дозволяє прогнозувати неперервні числові значення. Але багато задач машинного навчання вимагають від нас не передбачити число, а віднести об'єкт до певної **категорії** або **класу**. Наприклад, визначити, чи є лист спамом, чи ні; розпізнати цифру на зображенні; діагностувати наявність захворювання. Це – задачі **класифікації**.

Сьогодні ми:

1.  Познайомимося з **логістичною регресією** – популярним методом для вирішення задач класифікації.
2.  Розберемося, як **оцінювати якість** моделей класифікації (точність, повнота, F1-оцінка та ін.).
3.  Обговоримо проблеми **перенавчання та недонавчання**.
4.  З'ясуємо, навіщо потрібно **розділяти дані** на навчальну, валідаційну та тестову вибірки.

---

**Логістична регресія (Logistic Regression)**

Хоча назва містить слово "регресія", логістична регресія використовується для **класифікації**. Чому не можна просто використати лінійну регресію для класифікації (наприклад, намагаючись спрогнозувати 0 або 1)? Лінійна регресія може видавати значення більші за 1 або менші за 0, що не має сенсу для ймовірностей чи класів. Логістична регресія вирішує цю проблему.

* **Задача:** Найчастіше – **бінарна класифікація**, тобто віднесення об'єкта до одного з двох класів (наприклад, 0 або 1, "спам" або "не спам", "хворий" або "здоровий").
* **Ідея:** Замість того, щоб прямо прогнозувати клас, логістична регресія моделює **ймовірність** того, що об'єкт належить до класу "1".

* **Гіпотеза ($h_\theta(x)$):** Як отримати значення ймовірності (від 0 до 1) з лінійної комбінації ознак $\theta^T x$? Використовується спеціальна функція – **сигмоїда (Sigmoid)** або **логістична функція**.
    1.  Обчислюється лінійна комбінація: $z = \theta^T x = \theta_0 + \theta_1 x_1 + ... + \theta_n x_n$.
    2.  Результат $z$ "пропускається" через сигмоїдну функцію $g(z)$:
        $g(z) = \frac{1}{1 + e^{-z}}$
        * Графік сигмоїди має S-подібну форму.
        * Важливо: вона перетворює будь-яке дійсне число $z$ на значення в інтервалі **(0, 1)**.
        * Якщо $z$ велике додатне, $g(z) \approx 1$. Якщо $z$ велике від'ємне, $g(z) \approx 0$. Якщо $z=0$, $g(z) = 0.5$.
    3.  Таким чином, гіпотеза логістичної регресії:
        $h_\theta(x) = g(\theta^T x) = \frac{1}{1 + e^{-\theta^T x}}$
    * **Інтерпретація:** $h_\theta(x)$ оцінює ймовірність того, що об'єкт $x$ належить до класу 1: $h_\theta(x) \approx P(y=1 | x; \theta)$.

* **Прийняття рішення (Decision Boundary):** Щоб отримати кінцевий прогноз класу (0 або 1), ми встановлюємо **поріг** (зазвичай 0.5).
    * Якщо $h_\theta(x) \ge 0.5$, прогнозуємо $y=1$.
    * Якщо $h_\theta(x) < 0.5$, прогнозуємо $y=0$.
    * Зверніть увагу: $h_\theta(x) \ge 0.5$ тоді й тільки тоді, коли $\theta^T x \ge 0$. Рівняння $\theta^T x = 0$ визначає **межу прийняття рішень** (decision boundary) – лінію або гіперплощину, що розділяє класи в просторі ознак.

* **Функція втрат (Loss Function):** Використовувати MSE (як у лінійній регресії) для логістичної регресії недоцільно, оскільки функція втрат стає не опуклою, що ускладнює пошук мінімуму градієнтним спуском. Замість неї використовують **Логарифмічну функцію втрат (Log Loss)** або **Перехресну ентропію (Cross-Entropy)**.
    * Ідея: штрафувати модель сильніше, якщо вона дуже впевнено робить неправильний прогноз.
    * Втрати для одного прикладу:
        $Cost(h_\theta(x), y) = -y \log(h_\theta(x)) - (1-y) \log(1 - h_\theta(x))$
        * Якщо правильна мітка $y=1$: Cost = $-\log(h_\theta(x))$. Якщо прогноз $h_\theta(x)$ близький до 1 (правильно), то $\log(h_\theta(x)) \approx 0$, і втрати малі. Якщо $h_\theta(x)$ близький до 0 (неправильно), то $\log(h_\theta(x)) \to -\infty$, і втрати стають дуже великими.
        * Якщо правильна мітка $y=0$: Cost = $-\log(1 - h_\theta(x))$. Якщо прогноз $h_\theta(x)$ близький до 0 (правильно), то $1 - h_\theta(x) \approx 1$, $\log(1 - h_\theta(x)) \approx 0$, і втрати малі. Якщо $h_\theta(x)$ близький до 1 (неправильно), то $1 - h_\theta(x) \approx 0$, $\log(1 - h_\theta(x)) \to -\infty$, і втрати стають дуже великими.
    * **Загальна функція втрат (Cross-Entropy):** Середнє значення Log Loss по всіх $m$ навчальних прикладах:
        $J(\theta) = -\frac{1}{m} \sum_{i=1}^{m} [ y^{(i)} \log(h_\theta(x^{(i)})) + (1-y^{(i)}) \log(1 - h_\theta(x^{(i)})) ]$
    * Ця функція втрат є опуклою, що гарантує знаходження глобального мінімуму за допомогою градієнтного спуску.

* **Оптимізація:** Як і в лінійній регресії, ми знаходимо оптимальні параметри $\theta$, мінімізуючи функцію втрат $J(\theta)$ за допомогою **градієнтного спуску** або більш просунутих методів оптимізації. Правило оновлення параметрів має той самий вигляд $\theta_j := \theta_j - \alpha \frac{\partial J(\theta)}{\partial \theta_j}$, але обчислення похідної $\frac{\partial J(\theta)}{\partial \theta_j}$ враховує сигмоїду та логарифмічну функцію втрат.

* **Мультикласова класифікація (Multiclass Classification):** Коли класів більше двох (наприклад, розпізнавання цифр 0-9).
    * **Підхід "Один проти всіх" (One-vs-Rest / One-vs-All):** Навчаємо $K$ окремих бінарних логістичних регресій (де $K$ - кількість класів). $k$-та модель вчиться відрізняти клас $k$ від усіх інших класів разом узятих. Для нового прикладу обчислюємо ймовірності для всіх $K$ моделей і обираємо клас з найвищою ймовірністю.
    * (Існують і інші методи, наприклад, Softmax регресія, яка є прямим узагальненням логістичної регресії на багато класів).

---

**Оцінка моделей класифікації**

Як зрозуміти, наскільки добре працює наша модель класифікації? Простої точності (accuracy) часто буває недостатньо.

* **Проблема Accuracy на незбалансованих даних:** Уявіть задачу виявлення рідкісного захворювання (1% хворих, 99% здорових). Модель, яка *завжди* прогнозує "здоровий", матиме точність (accuracy) 99%! Але вона абсолютно марна для виявлення хворих.

* **Матриця помилок (Confusion Matrix):** Це таблиця, яка допомагає візуалізувати ефективність класифікатора. Для бінарної класифікації (класи 1 - Positive, 0 - Negative):

    |                   | Прогноз: Positive (1) | Прогноз: Negative (0) |
    | :---------------- | :-------------------- | :-------------------- |
    | **Реальність: Positive (1)** | True Positive (TP)    | False Negative (FN)   |
    | **Реальність: Negative (0)** | False Positive (FP)   | True Negative (TN)    |

    * **TP (Істинно позитивні):** Правильно класифіковані як позитивні (хворий -> хворий).
    * **TN (Істинно негативні):** Правильно класифіковані як негативні (здоровий -> здоровий).
    * **FP (Хибно позитивні / Помилка I роду):** Негативні класифіковані як позитивні (здоровий -> хворий).
    * **FN (Хибно негативні / Помилка II роду):** Позитивні класифіковані як негативні (хворий -> здоровий).

* **Метрики на основі матриці помилок:**
    * **Accuracy (Загальна точність):** Частка всіх правильних прогнозів.
        $Accuracy = \frac{TP + TN}{TP + TN + FP + FN}$
        (Як ми бачили, може бути оманливою).
    * **Precision (Точність для класу 1):** Яка частка об'єктів, названих класифікатором позитивними, дійсно є позитивними?
        $Precision = \frac{TP}{TP + FP}$
        (Важлива, коли ціна FP висока. Приклад: відфільтрувати якомога менше важливих листів у спам).
    * **Recall (Повнота / Чутливість / True Positive Rate):** Яку частку позитивних об'єктів класифікатор зміг правильно виявити?
        $Recall = \frac{TP}{TP + FN}$
        (Важлива, коли ціна FN висока. Приклад: не пропустити хворого пацієнта при діагностиці).
    * **F1-Score:** Середнє гармонійне Precision та Recall. Дає баланс між ними.
        $F1 = 2 \cdot \frac{Precision \cdot Recall}{Precision + Recall}$
        (Корисна, коли важливі і Precision, і Recall).

* **AUC - ROC (Area Under the Receiver Operating Characteristic Curve):**
    * **ROC-крива:** Графік, що показує співвідношення між True Positive Rate (Recall) та False Positive Rate ($FPR = \frac{FP}{FP+TN}$) при зміні порогу прийняття рішень класифікатора.
    * **AUC (Площа під ROC-кривою):** Число від 0 до 1, що показує загальну якість моделі у розрізненні класів незалежно від порогу. 1 – ідеальний класифікатор, 0.5 – випадкове вгадування. Добре працює для незбалансованих даних.

Вибір метрики залежить від конкретної задачі та того, які помилки (FP чи FN) є більш критичними.

---

**Проблема перенавчання та недонавчання (Overfitting & Underfitting)**

Це дві поширені проблеми при побудові моделей ML.

* **Недонавчання (Underfitting / Високий Bias):** Модель **занадто проста**, щоб вловити складні залежності в даних. Вона погано працює як на навчальних, так і на нових (тестових) даних.
    * *Причина:* Модель має недостатню "потужність" (наприклад, лінійна модель для нелінійних даних).
    * *Як боротися:* Використати складнішу модель, додати більше релевантних ознак, зменшити регуляризацію (про це пізніше).

* **Перенавчання (Overfitting / Висока Variance):** Модель **занадто складна** і "запам'ятовує" навчальні дані, включаючи шум та випадкові викиди, замість того, щоб узагальнювати закономірності. Вона показує чудові результати на навчальних даних, але **погано працює на нових даних**.
    * *Причина:* Модель занадто гнучка, навчальних даних недостатньо.
    * *Як боротися:*
        * Зібрати більше навчальних даних.
        * Використати простішу модель.
        * **Регуляризація:** Додати "штраф" до функції втрат за великі значення параметрів моделі (змушує модель бути "простішою").
        * Методи крос-валідації (про це пізніше).
        * Рання зупинка навчання (Early Stopping).

* **Хороша модель (Good Fit):** Знаходить баланс між недонавчанням та перенавчанням, добре узагальнює закономірності та показує хороші результати як на навчальних, так і на нових даних.

---

**Розділення даних на навчальну, валідаційну та тестову вибірки**

Щоб об'єктивно оцінити якість моделі та уникнути перенавчання при виборі найкращої моделі чи її параметрів, **ніколи не можна оцінювати модель на тих самих даних, на яких вона навчалася!** Тому дані зазвичай розділяють на три частини:

1.  **Навчальна вибірка (Training Set):** Найбільша частина даних (зазвичай ~60-80%). Використовується безпосередньо для "навчання" моделі – підбору її параметрів $\theta$ (наприклад, за допомогою градієнтного спуску).
2.  **Валідаційна вибірка (Validation Set / Dev Set):** Невелика частина даних (~10-20%). **Не використовується для навчання параметрів $\theta$**. Використовується для:
    * Налаштування **гіперпараметрів** моделі (тих, що не вивчаються автоматично, наприклад, швидкість навчання $\alpha$, ступінь поліному, параметр регуляризації).
    * Вибору **найкращої моделі** з кількох варіантів.
    * Ранньої зупинки навчання для боротьби з перенавчанням.
    Модель оцінюється на валідаційній вибірці багато разів під час процесу розробки.
3.  **Тестова вибірка (Test Set):** Невелика частина даних (~10-20%). **Не використовується ні для навчання $\theta$, ні для налаштування гіперпараметрів.** Використовується **лише один раз** наприкінці розробки, щоб отримати фінальну, **неупереджену оцінку** продуктивності обраної та налаштованої моделі на даних, яких вона раніше "не бачила".

Такий поділ є критично важливим для побудови моделей, які будуть добре працювати в реальних умовах.

---

**Підсумки**

* **Логістична регресія** використовує **сигмоїдну функцію** для моделювання ймовірності належності до класу і є базовим методом для **класифікації**. Навчається за допомогою мінімізації **перехресної ентропії**.
* Оцінювати моделі класифікації потрібно за допомогою відповідних метрик (**Accuracy, Precision, Recall, F1-Score, AUC**), вибір яких залежить від задачі, особливо при роботі з незбалансованими даними.
* **Перенавчання** (модель занадто складна, погано генералізує) та **недонавчання** (модель занадто проста) – ключові проблеми ML, які потрібно вміти діагностувати та долати.
* Правильне **розділення даних** на навчальну, валідаційну та тестову вибірки є необхідним для об'єктивної оцінки та вибору моделі.

Сьогодні ми зробили ще один крок у світ машинного навчання, перейшовши до задач класифікації та обговоривши важливі аспекти оцінки та надійності моделей.

**Наступні кроки**

* Подумайте, для яких задач з вашого життя чи роботи можна було б застосувати логістичну регресію.
* Які метрики (Precision чи Recall) були б важливішими при розробці спам-фільтра? А при розробці системи медичної діагностики?
* На наступних лекціях ми можемо розглянути інші моделі машинного навчання або заглибитись в методи боротьби з перенавчанням, такі як регуляризація.

---

Дякую за увагу! Я готовий відповісти на ваші запитання.