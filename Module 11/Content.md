**Лекція 11: Нейронні мережі - Навчання (Backpropagation) та оптимізатори**

**Мета лекції:** Пояснити, як відбувається процес навчання штучних нейронних мереж. Розглянути вибір функції втрат, інтуїтивно зрозуміти ключовий алгоритм зворотного поширення помилки (Backpropagation) для обчислення градієнтів. Ознайомитися з сучасними оптимізаторами, що покращують градієнтний спуск, та методами регуляризації для боротьби з перенавчанням.

---

Доброго дня! Минулого разу ми з вами збудували нейронну мережу: познайомилися зі штучними нейронами, функціями активації, багатошаровою архітектурою та процесом прямого поширення, який дозволяє мережі генерувати прогноз для заданого входу. Але як зробити так, щоб ці прогнози були точними? Як налаштувати мільйони ваг та зміщень у мережі, щоб вона правильно вирішувала поставлену задачу? Сьогодні ми зануримося у процес **навчання** нейронних мереж.

Ми дізнаємось про:

1.  **Функції втрат:** Як виміряти помилку мережі?
2.  **Зворотне поширення помилки (Backpropagation):** Як ефективно обчислити, наскільки кожен параметр мережі впливає на цю помилку?
3.  **Оптимізатори:** Як ефективно оновлювати параметри, щоб зменшити помилку?
4.  **Регуляризацію:** Як запобігти "перенавчанню" мережі?

---

**Функція втрат для нейронних мереж (Loss Function)**

Перший крок у навчанні – це визначити, наскільки погано (або добре) працює наша мережа з поточними параметрами. Для цього використовується **функція втрат (Loss Function)**, або **функція вартості (Cost Function)**, $J$. Вона обчислює "відстань" або розбіжність між прогнозами мережі ($\hat{y}$) та істинними значеннями ($y$) на навчальних даних. **Мета навчання – знайти такі параметри (ваги та зміщення), які мінімізують значення цієї функції втрат.**

Вибір функції втрат залежить від типу задачі, яку вирішує мережа:

* **Для задач регресії** (прогноз неперервного значення):
    * **Середня квадратична помилка (Mean Squared Error - MSE):** $J = \frac{1}{m} \sum_{i=1}^{m} (\hat{y}^{(i)} - y^{(i)})^2$. (Іноді з коефіцієнтом $1/2$ перед сумою). Штрафує за великі помилки сильніше.
    * **Середня абсолютна помилка (Mean Absolute Error - MAE):** $J = \frac{1}{m} \sum_{i=1}^{m} |\hat{y}^{(i)} - y^{(i)}|$. Менш чутлива до викидів у даних порівняно з MSE.

* **Для задач бінарної класифікації** (вихідний шар з Sigmoid):
    * **Бінарна перехресна ентропія (Binary Cross-Entropy / Log Loss):** $J = -\frac{1}{m} \sum_{i=1}^{m} [ y^{(i)} \log(\hat{y}^{(i)}) + (1-y^{(i)}) \log(1 - \hat{y}^{(i)}) ]$. Вимірює розбіжність між прогнозованою ймовірністю $\hat{y}^{(i)}$ та істинною міткою $y^{(i)}$ (0 або 1).

* **Для задач мультикласової класифікації** (вихідний шар з Softmax):
    * **Категоріальна перехресна ентропія (Categorical Cross-Entropy):** Узагальнення бінарної версії на $K$ класів. $J = -\frac{1}{m} \sum_{i=1}^{m} \sum_{k=1}^{K} y_k^{(i)} \log(\hat{y}_k^{(i)})$. Де $y_k^{(i)}$ – індикатор (1, якщо $i$-й приклад належить до класу $k$, і 0 інакше), $\hat{y}_k^{(i)}$ – прогнозована ймовірність класу $k$.

Функція втрат визначає "ландшафт", по якому ми будемо рухатись за допомогою оптимізатора, щоб знайти його найнижчу точку.

---

**Алгоритм зворотного поширення помилки (Backpropagation)**

Отже, ми маємо функцію втрат $J$. Щоб мінімізувати її за допомогою градієнтного спуску, нам потрібно обчислити градієнт $J$ по відношенню до **кожного** параметра (ваги $w$ та зміщення $b$) у **всій** мережі. У глибоких мережах таких параметрів можуть бути мільйони. Робити це "в лоб" неефективно.

**Backpropagation (BP)** – це ефективний алгоритм для обчислення цих градієнтів. Він використовує **ланцюгове правило (Chain Rule)** з диференціального числення для поширення сигналу помилки **назад** через мережу – від вихідного шару до вхідного.

* **Інтуїтивне пояснення:**
    1.  **Пряме поширення (Forward Pass):** Спочатку ми пропускаємо вхідний приклад $x$ через мережу (як ми робили минулого разу), щоб отримати прогноз $\hat{y}$.
    2.  **Обчислення помилки на виході:** Розраховуємо значення функції втрат $J$, порівнюючи $\hat{y}$ з істинним значенням $y$. Також обчислюємо, наскільки вихідний сигнал мережі ($\hat{y}$ або активація останнього шару $a^{[L]}$) впливає на цю помилку (тобто $\frac{\partial J}{\partial a^{[L]}}$).
    3.  **Поширення помилки назад (Backward Pass):**
        * **Останній шар (L):** Знаючи, як помилка залежить від активації $a^{[L]}$, і знаючи, як $a^{[L]}$ залежить від зваженої суми $z^{[L]}$ (через функцію активації $g^{[L]}$), а $z^{[L]}$ – від ваг $W^{[L]}$ та зміщень $b^{[L]}$, ми за ланцюговим правилом обчислюємо градієнти $\frac{\partial J}{\partial W^{[L]}}$ та $\frac{\partial J}{\partial b^{[L]}}$. Також обчислюємо, як помилка залежить від активації *попереднього* шару $a^{[L-1]}$.
        * **Попередній шар (L-1):** Використовуючи інформацію про вплив $a^{[L-1]}$ на помилку (отриману з шару L), ми аналогічно за ланцюговим правилом обчислюємо градієнти $\frac{\partial J}{\partial W^{[L-1]}}$, $\frac{\partial J}{\partial b^{[L-1]}}$ і визначаємо вплив на помилку активації ще попереднішого шару $a^{[L-2]}$.
        * **Повторення:** Цей процес повторюється шар за шаром назад до самого першого прихованого шару.
    4.  **Результат:** Після повного проходу назад ми маємо градієнти функції втрат по відношенню до всіх ваг та зміщень у мережі.

* **Значення:** Backpropagation дозволяє обчислити всі необхідні градієнти за час, порівнянний з часом одного прямого проходу через мережу. Це робить можливим тренування глибоких нейронних мереж за допомогою градієнтного спуску.

---

**Оптимізатори (Optimizers)**

Маючи градієнти, ми можемо оновлювати параметри за допомогою градієнтного спуску: $\theta := \theta - \alpha \nabla J(\theta)$. Однак базовий градієнтний спуск (особливо його "пакетна" версія, що використовує весь датасет для одного кроку) може бути повільним і неефективним на складних "ландшафтах" функції втрат. Тому були розроблені більш просунуті **оптимізатори**:

1.  **Стохастичний градієнтний спуск (Stochastic Gradient Descent - SGD):**
    * **Ідея:** Замість обчислення градієнта по всьому датасету на кожному кроці, SGD оновлює параметри на основі градієнта, обчисленого лише по **одному випадковому прикладу** (або невеликій підмножині – **mini-batch SGD**).
    * **Переваги:** Набагато швидші ітерації, дозволяє обробляти величезні датасети. "Шум" в оцінці градієнта допомагає вибиратися з неглибоких локальних мінімумів.
    * **Недоліки:** "Шумний" рух до мінімуму (траєкторія може сильно коливатися). Часто потребує налаштування швидкості навчання (learning rate decay).

2.  **SGD з імпульсом (SGD with Momentum):**
    * **Ідея:** Додає "інерцію" до руху. Оновлення параметрів залежить не лише від поточного градієнта, але й від "швидкості", накопиченої на попередніх кроках.
    * **Ефект:** Згладжує коливання SGD, прискорює рух у стабільних напрямках. Допомагає швидше долати плато та неглибокі мінімуми.

3.  **RMSprop (Root Mean Square Propagation):**
    * **Ідея:** Адаптує швидкість навчання **для кожного параметра окремо**. Зменшує швидкість навчання для параметрів, у яких градієнти зазвичай великі, і збільшує для параметрів з малими градієнтами.
    * **Ефект:** Допомагає збалансувати навчання для різних параметрів, особливо корисно при роботі з розрідженими даними.

4.  **Adam (Adaptive Moment Estimation):**
    * **Ідея:** **Найпопулярніший** сучасний оптимізатор. Комбінує ідеї Momentum (зберігає інформацію про середній градієнт) та RMSprop (зберігає інформацію про середній квадрат градієнта).
    * **Переваги:** Зазвичай добре працює "з коробки" з типовими налаштуваннями гіперпараметрів (швидкість навчання $\alpha$ тощо). Ефективний на широкому колі задач.
    * **Недоліки:** Іноді може збігатися до "гірших" мінімумів порівняно з SGD з ретельно налаштованим Momentum.

**Висновок:** Сучасні оптимізатори роблять процес навчання нейронних мереж значно швидшим та стабільнішим порівняно з базовим градієнтним спуском. Adam часто є хорошим вибором для початку.

---

**Регуляризація в нейронних мережах (Regularization)**

Як ми обговорювали минулого разу, **перенавчання (overfitting)** – серйозна проблема, коли модель стає занадто складною і добре працює на навчальних даних, але погано генералізує на нових. **Регуляризація** – це набір технік, спрямованих на боротьбу з перенавчанням шляхом додавання певних обмежень або "штрафів" до процесу навчання.

* **L1 та L2 регуляризація:**
    * **Ідея:** Додати до функції втрат $J(\theta)$ додатковий член, який штрафує за великі значення ваг $w$. Це спонукає мережу знаходити "простіші" рішення з меншими вагами.
    * **L2 Регуляризація (Weight Decay):** Додає штраф, пропорційний **сумі квадратів** усіх ваг: $J_{reg} = J(\theta) + \frac{\lambda}{2m} \sum w^2$. $\lambda$ – гіперпараметр, що контролює силу регуляризації. Найпоширеніший тип.
    * **L1 Регуляризація:** Додає штраф, пропорційний **сумі модулів** усіх ваг: $J_{reg} = J(\theta) + \frac{\lambda}{m} \sum |w|$. Має властивість "зануляти" деякі ваги, що може використовуватись для відбору ознак, але на практиці L2 часто працює краще для нейромереж.

* **Dropout:**
    * **Ідея:** **Дуже ефективна і проста** техніка. Під час **кожної ітерації навчання** випадковим чином "виключати" (встановлювати їх вихід в 0) певну частку нейронів у прихованих шарах (наприклад, 20% чи 50%). Виключені нейрони не беруть участі ні у прямому, ні у зворотному поширенні на цій ітерації.
    * **Ефект:** Змушує мережу навчатися більш **надлишкових представлень**, оскільки вона не може покладатися на наявність конкретних нейронів. Можна розглядати як навчання ансамблю з багатьох "проріджених" мереж.
    * **Важливо:** Dropout застосовується **лише під час навчання**. Під час тестування (оцінки) всі нейрони використовуються, але їх виходи масштабуються, щоб компенсувати відсутність dropout.

* **Інші техніки:** Рання зупинка (Early Stopping – припинення навчання, коли помилка на валідаційній вибірці починає зростати), аугментація даних (штучне збільшення обсягу навчальних даних шляхом їх модифікації) тощо.

Регуляризація є невід'ємною частиною тренування сучасних глибоких нейронних мереж для досягнення хорошої генералізації.

---

**Підсумки**

* Навчання нейронної мережі полягає у мінімізації **функції втрат**, яка вимірює помилку між прогнозами та істинними значеннями.
* Алгоритм **зворотного поширення помилки (Backpropagation)** ефективно обчислює градієнти функції втрат по відношенню до всіх параметрів мережі, використовуючи ланцюгове правило.
* **Оптимізатори** (SGD, Momentum, RMSprop, **Adam**) покращують процес градієнтного спуску, роблячи навчання швидшим та стабільнішим.
* **Регуляризація** (**L1/L2**, **Dropout**) допомагає боротися з **перенавчанням**, змушуючи модель краще узагальнювати результати на нових даних.

Процес навчання нейронної мережі – це складний танець між прямим поширенням, обчисленням втрат, зворотним поширенням градієнтів та їх оновленням за допомогою оптимізатора, часто з використанням технік регуляризації.

**Наступні кроки**

* Подумайте, чому обчислення градієнтів є ключовим для навчання моделей на основі градієнтного спуску.
* Які переваги дає використання оптимізаторів типу Adam порівняно з простим SGD?
* На наступних лекціях ми можемо перейти до розгляду конкретних архітектур нейронних мереж, таких як згорткові (для зображень) або рекурентні (для послідовностей).

---

Дякую за увагу! Я готовий відповісти на ваші запитання.