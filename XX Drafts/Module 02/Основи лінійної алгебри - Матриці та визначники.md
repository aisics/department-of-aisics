Гаразд, повертаємось до нашої подорожі основами математики для штучного інтелекту! На минулій лекції ми познайомилися з векторами – впорядкованими наборами чисел, що слугують для представлення даних або напрямків.

Але що робити, коли даних стає більше, і вони мають певну структуру? Уявіть собі зображення: це ж не просто довгий список пікселів, а прямокутна сітка. Або якщо нам потрібно описати не один об'єкт багатьма ознаками, а одразу цілий набір об'єктів? Або, що ще важливіше, як описати *операції* над векторами – наприклад, поворот або масштабування в просторі?

Тут на сцену виходять **матриці**. Якщо дуже спрощено, матриця – це **прямокутна таблиця чисел**. Вона дозволяє нам організовувати вектори разом, представляти складніші набори даних та, що критично важливо, описувати **лінійні перетворення** векторів.

В штучному інтелекті матриці – це справді всюдисущий інструмент. Вони використовуються для:

* Зберігання та маніпулювання даними (пікселі зображення, таблиці даних).
* Представлення "знань" нейронної мережі (так звані матриці ваг).
* Опису трансформацій даних (наприклад, зміна розміру чи орієнтації зображення).
* Розв'язання систем лінійних рівнянь, що виникають в процесі оптимізації моделей.

Разом з матрицями ми сьогодні познайомимося і з **визначниками (детермінантами)**. Це спеціальне число, яке можна обчислити для *квадратних* матриць, і воно несе в собі важливу інформацію про властивості самої матриці та перетворення, яке вона задає.

**Отже, наш план на сьогодні:**

1.  Зрозуміти, що таке матриця, яка її розмірність та які бувають спеціальні типи матриць.
2.  Освоїти основні операції: додавання, віднімання, множення на число та найважливіше – **матричне множення**.
3.  Навчитись знаходити **транспоновану** матрицю.
4.  Дізнатись, що таке **визначник** (детермінант) і як його обчислити для матриць $2 \times 2$ та $3 \times 3$.
5.  Розглянути деякі властивості визначників.

Поїхали!

---

**1. Поняття матриці**

* **Визначення:** **Матриця** – це прямокутна таблиця чисел (або інших математичних об'єктів), організованих у **рядки** та **стовпці**.
* **Позначення:** Матриці зазвичай позначають великими латинськими літерами (наприклад, $A, B, W$). Елемент матриці $A$, що стоїть на перетині $i$-го рядка та $j$-го стовпця, позначається як $a_{ij}$ або $A_{ij}$. Нумерація рядків іде згори вниз, стовпців – зліва направо.
* **Розмірність:** Розмір матриці визначається парою чисел: кількість рядків $\times$ кількість стовпців. Якщо матриця $A$ має $m$ рядків і $n$ стовпців, її розмір – $m \times n$ (читається "m на n").
* **Приклад:**
    $$A = \begin{pmatrix} 5 & -1 & 0 \\ 3 & 2 & 7 \end{pmatrix}$$
    Це матриця розміром $2 \times 3$. Тут $a_{11}=5$, $a_{12}=-1$, $a_{23}=7$.
* **Зв'язок з векторами:** Матрицю можна розглядати як набір векторів. Рядки матриці – це **вектор-рядки**, а стовпці – **вектор-стовпці**. У прикладі вище, вектор-рядок 1: $[5, -1, 0]$, вектор-стовпець 1: $\begin{pmatrix} 5 \\ 3 \end{pmatrix}$.
* **Застосування в AI:**
    * **Зображення:** Чорно-біле зображення можна представити як матрицю, де кожен елемент $a_{ij}$ – це яскравість пікселя в $i$-му рядку та $j$-му стовпці. Для кольорового зображення використовують три матриці (для червоного, зеленого, синього каналів) або тривимірну структуру (тензор).
    * **Дані:** Набір даних, де кожен рядок відповідає окремому спостереженню (наприклад, клієнту), а кожен стовпець – певній ознаці (вік, стать, сума покупки), природно представляється у вигляді матриці.
    * **Нейронні мережі:** Зв'язки між нейронами у сусідніх шарах часто представлені матрицею ваг $W$, де $w_{ij}$ – це "сила" зв'язку від $j$-го нейрона попереднього шару до $i$-го нейрона поточного шару.

---

**2. Операції над матрицями**

* **Додавання та віднімання:**
    * **Умова:** Можна додавати або віднімати тільки матриці **однакового розміру** ($m \times n$).
    * **Правило:** Операція виконується **поелементно**. Тобто, щоб знайти елемент суми (або різниці) $c_{ij}$, потрібно додати (або відняти) відповідні елементи $a_{ij}$ та $b_{ij}$.
    * **Приклад:**
        $$\begin{pmatrix} 2 & 0 \\ -1 & 3 \end{pmatrix} + \begin{pmatrix} 1 & 4 \\ 2 & -1 \end{pmatrix} = \begin{pmatrix} 2+1 & 0+4 \\ -1+2 & 3+(-1) \end{pmatrix} = \begin{pmatrix} 3 & 4 \\ 1 & 2 \end{pmatrix}$$
* **Множення матриці на скаляр (число):**
    * **Правило:** Щоб помножити матрицю $A$ на число $c$, потрібно **кожен елемент матриці** $A$ помножити на це число $c$.
    * **Приклад:**
        $$-2 \cdot \begin{pmatrix} 1 & -3 & 0 \\ 4 & 5 & -2 \end{pmatrix} = \begin{pmatrix} -2\cdot1 & -2\cdot(-3) & -2\cdot0 \\ -2\cdot4 & -2\cdot5 & -2\cdot(-2) \end{pmatrix} = \begin{pmatrix} -2 & 6 & 0 \\ -8 & -10 & 4 \end{pmatrix}$$
* **Множення матриць (Матричне множення):**
    * **Увага!** Це найважливіша, але й найменш інтуїтивна операція.
    * **Умова:** Матрицю $A$ розміром $m \times \color{red}{k}$ можна помножити на матрицю $B$ розміром $\color{red}{k} \times n$ тільки тоді, коли **кількість стовпців першої матриці ($k$) дорівнює кількості рядків другої матриці ($k$)**.
    * **Результат:** Результатом буде матриця $C = A \cdot B$ розміром $m \times n$.
    * **Правило обчислення елемента $c_{ij}$:** Елемент $c_{ij}$ матриці $C$, що стоїть в $i$-му рядку та $j$-му стовпці, обчислюється як **скалярний добуток $i$-го рядка матриці $A$ на $j$-й стовпець матриці $B$**. (Нагадаю, скалярний добуток векторів $[x_1, ..., x_k]$ та $[y_1, ..., y_k]$ – це $x_1 y_1 + ... + x_k y_k$).
    * **Формула:** $c_{ij} = \sum_{p=1}^{k} a_{ip} b_{pj}$
    * **Приклад ($2 \times 2$ на $2 \times 2$):**
        $$A = \begin{pmatrix} 1 & 2 \\ 3 & 0 \end{pmatrix}, \quad B = \begin{pmatrix} 4 & -1 \\ 2 & 5 \end{pmatrix}$$
        $$C = A \cdot B = \begin{pmatrix} \dots & \dots \\ \dots & \dots \end{pmatrix}$$
        * $c_{11}$ ($1$-й рядок $A$ на $1$-й стовпець $B$): $(1 \cdot 4) + (2 \cdot 2) = 4 + 4 = 8$
        * $c_{12}$ ($1$-й рядок $A$ на $2$-й стовпець $B$): $(1 \cdot -1) + (2 \cdot 5) = -1 + 10 = 9$
        * $c_{21}$ ($2$-й рядок $A$ на $1$-й стовпець $B$): $(3 \cdot 4) + (0 \cdot 2) = 12 + 0 = 12$
        * $c_{22}$ ($2$-й рядок $A$ на $2$-й стовпець $B$): $(3 \cdot -1) + (0 \cdot 5) = -3 + 0 = -3$
        $$C = \begin{pmatrix} 8 & 9 \\ 12 & -3 \end{pmatrix}$$
    * **Важлива властивість:** Матричне множення **не комутативне**, тобто, загалом, $A \cdot B \neq B \cdot A$. Порядок множників має значення! (Перевірте самі, перемноживши $B \cdot A$ у прикладі вище).
    * **Застосування в AI:** Це ключова операція!
        * **Лінійні трансформації:** Якщо вектор $x$ представляє точку, а матриця $W$ – операцію (поворот, масштабування), то новий вектор $y$ після трансформації обчислюється як $y = W \cdot x$. (Вектор-стовпець $x$ розглядається як матриця $k \times 1$).
        * **Нейронні мережі:** Обчислення виходу шару нейронів – це, по суті, матричне множення вектора входів на матрицю ваг шару (з подальшим застосуванням функції активації): $output = activation(W \cdot input + b)$.

---

**3. Транспонування матриці**

* **Визначення:** Транспонування матриці $A$ – це операція, при якій її **рядки стають стовпцями**, а **стовпці – рядками**.
* **Позначення:** $A^T$.
* **Правило:** Якщо $A$ має розмір $m \times n$, то $A^T$ матиме розмір $n \times m$. Елемент $(A^T)_{ij}$ (в $i$-му рядку, $j$-му стовпці транспонованої матриці) дорівнює елементу $a_{ji}$ (в $j$-му рядку, $i$-му стовпці вихідної матриці).
* **Приклад:**
    $$A = \begin{pmatrix} 1 & 2 & 3 \\ 4 & 5 & 6 \end{pmatrix} \quad \implies \quad A^T = \begin{pmatrix} 1 & 4 \\ 2 & 5 \\ 3 & 6 \end{pmatrix}$$
* **Застосування в AI:** Транспонування використовується в багатьох формулах і алгоритмах, наприклад, при обчисленні градієнтів для навчання нейронних мереж, у формулах лінійної регресії, при роботі з коваріаційними матрицями.

---

**4. Спеціальні типи матриць**

* **Квадратна матриця:** Матриця, у якої кількість рядків дорівнює кількості стовпців ($m=n$). Розмір $n \times n$. Тільки для квадратних матриць визначається детермінант та обернена матриця.
* **Головна діагональ:** Елементи $a_{ii}$ (де номер рядка дорівнює номеру стовпця) у квадратній матриці.
* **Діагональна матриця:** Квадратна матриця, у якої всі елементи поза головною діагоналлю дорівнюють нулю.
    $$D = \begin{pmatrix} 7 & 0 & 0 \\ 0 & -2 & 0 \\ 0 & 0 & 3 \end{pmatrix}$$
* **Одинична матриця ($I$ або $E$):** Діагональна матриця, у якої всі елементи на головній діагоналі дорівнюють 1. Розмір $n \times n$. Вона є **нейтральним елементом для матричного множення** (як число 1 для звичайного множення): $A \cdot I = I \cdot A = A$.
    $$I_3 = \begin{pmatrix} 1 & 0 & 0 \\ 0 & 1 & 0 \\ 0 & 0 & 1 \end{pmatrix}$$
* **Симетрична матриця:** Квадратна матриця, яка дорівнює своїй транспонованій ($A = A^T$). Тобто $a_{ij} = a_{ji}$ для всіх $i, j$. Елементи симетричні відносно головної діагоналі. (Наприклад, матриці відстаней або матриці коваріації в статистиці є симетричними).
    $$S = \begin{pmatrix} 1 & 5 & -2 \\ 5 & 7 & 3 \\ -2 & 3 & 0 \end{pmatrix}$$

---

**5. Визначник (Детермінант) матриці**

* **Поняття:** **Визначник** (або **детермінант**) – це **число**, яке можна обчислити **тільки для квадратної матриці**. Воно характеризує важливі властивості матриці та лінійного перетворення, яке вона представляє.
* **Позначення:** $\det(A)$ або $|A|$.
* **Геометричний сенс (для $2 \times 2$ та $3 \times 3$):**
    * Абсолютне значення визначника $|\det(A)|$ показує, **у скільки разів матриця $A$ змінює площу** (для $2 \times 2$) або **об'єм** (для $3 \times 3$) фігур при відповідному лінійному перетворенні.
    * Якщо $\det(A) = 0$, це означає, що перетворення "схлопує" простір в меншу розмірність (наприклад, площину перетворює в лінію або точку). Така матриця називається **виродженою** або **сингулярною**.
    * Знак визначника ($\det(A) > 0$ або $\det(A) < 0$) показує, чи зберігається **орієнтація** простору (наприклад, чи не відбувається "віддзеркалення").
* **Обчислення для $2 \times 2$:**
    * **Формула:** Для $ A = \begin{pmatrix} a & b \\ c & d \end{pmatrix} $, визначник $\det(A) = ad - bc$. (Добуток елементів на головній діагоналі мінус добуток елементів на побічній діагоналі).
    * **Приклад:**
        $$A = \begin{pmatrix} 3 & -1 \\ 2 & 4 \end{pmatrix} \implies \det(A) = (3)(4) - (-1)(2) = 12 - (-2) = 14$$
* **Обчислення для $3 \times 3$ (Правило Саррюса або правило трикутників):**
    * **Формула:** Для $ A = \begin{pmatrix} a & b & c \\ d & e & f \\ g & h & i \end{pmatrix} $:
        $$\det(A) = aei + bfg + cdh - ceg - bdi - afh$$
    * **Мнемонічне правило (Саррюса):** Допишіть перші два стовпці матриці справа. Потім обчисліть суму добутків елементів вздовж трьох головних діагоналей (зліва направо вниз) і відніміть суму добутків елементів вздовж трьох побічних діагоналей (справа наліво вниз).
        *(Візуалізація: показати на прикладі)*
    * **Приклад:**
        $$A = \begin{pmatrix} 2 & 1 & 0 \\ -1 & 3 & 4 \\ 0 & 5 & -2 \end{pmatrix}$$
        $$\det(A) = (2)(3)(-2) + (1)(4)(0) + (0)(-1)(5) - (0)(3)(0) - (1)(-1)(-2) - (2)(4)(5)$$
        $$\det(A) = -12 + 0 + 0 - 0 - 2 - 40 = -54$$
* **Визначники для більших матриць:** Обчислюються складнішими методами, наприклад, через розклад за рядком чи стовпцем з використанням мінорів та алгебраїчних доповнень (ми не будемо заглиблюватися в це зараз).
* **Деякі властивості визначників:**
    * $\det(A^T) = \det(A)$ (Визначник не змінюється при транспонуванні).
    * $\det(A \cdot B) = \det(A) \cdot \det(B)$ (Визначник добутку матриць дорівнює добутку їх визначників).
    * Якщо матриця має нульовий рядок або стовпець, її визначник дорівнює 0.
    * Якщо один рядок (стовпець) матриці є лінійною комбінацією інших рядків (стовпців), зокрема, якщо два рядки (стовпці) однакові або пропорційні, то визначник дорівнює 0.
    * $\det(I) = 1$ (Визначник одиничної матриці дорівнює 1).
* **Застосування в AI:**
    * **Перевірка виродженості:** $\det(A) = 0$ є критерієм того, що матриця вироджена. Це важливо, наприклад, при розв'язанні систем лінійних рівнянь $Ax=b$ (якщо $\det(A)=0$, система може не мати єдиного розв'язку) та при знаходженні оберненої матриці (вона існує тільки якщо $\det(A) \neq 0$).
    * Використовується в деяких алгоритмах машинного навчання та аналізу даних (наприклад, в методі головних компонент (PCA) для аналізу коваріаційної матриці).

---

**Підсумок**

Сьогодні ми зробили ще один важливий крок, познайомившись із **матрицями** – прямокутними таблицями чисел, які є фундаментальним інструментом для представлення структурованих даних та лінійних перетворень в AI. Ми розглянули основні операції, серед яких критично важливим є **матричне множення**, та різні типи матриць. Також ми дізналися про **визначник** – числову характеристику квадратної матриці, яка показує, як перетворення змінює площу/об'єм і чи є матриця виродженою.

Запам'ятайте: матриці та операції з ними – це основа багатьох обчислень в машинному навчанні, особливо в глибокому навчанні та нейронних мережах. Розуміння того, як вони працюють, допомагає краще усвідомити внутрішню логіку алгоритмів AI.

Наступного разу ми розглянемо, як матриці та визначники допомагають розв'язувати системи лінійних рівнянь та що таке обернена матриця.

Дякую! Не забуваємо про вподобайку, поширення та чесний відгук чи запитання в коментарях, до зустрічі!