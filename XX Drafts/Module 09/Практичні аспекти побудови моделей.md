**Лекція 9.3: Практичні аспекти побудови моделей**

**Мета лекції:** Перейти від теорії алгоритмів машинного навчання до практичних кроків, необхідних для побудови ефективних моделей. Розглянути ключові етапи: створення та вибір найкращих ознак (інженерія та відбір ознак), надійна оцінка якості моделі (крос-валідація) та пошук оптимальних налаштувань для алгоритмів (налаштування гіперпараметрів).

---

Доброго дня! На попередніх лекціях ми познайомилися з цілим арсеналом алгоритмів машинного навчання – від лінійних моделей та дерев рішень до KNN та SVM. Знати, як працюють ці алгоритми – це важливо, але щоб змусити їх добре працювати на реальних даних, потрібні певні практичні навички та методики. Саме про них ми сьогодні й поговоримо.

Незалежно від того, чи створюєте ви модель для аналізу даних у львівській компанії, чи працюєте над глобальним проектом, сьогодні, 17 квітня 2025 року, ці практичні аспекти є ключовими для успіху в галузі ШІ. Ми зосередимось на чотирьох важливих етапах:

1.  **Інженерія ознак (Feature Engineering):** Як підготувати "сировину" (дані) для моделі?
2.  **Відбір ознак (Feature Selection):** Як вибрати найкориснішу інформацію?
3.  **Крос-валідація (Cross-Validation):** Як надійно оцінити якість моделі?
4.  **Налаштування гіперпараметрів (Hyperparameter Tuning):** Як знайти найкращі "налаштування" для нашого алгоритму?

Освоєння цих технік часто має більший вплив на кінцевий результат, ніж вибір самого алгоритму.

---

**Інженерія ознак (Feature Engineering)**

* **Що це?** Процес використання знань про предметну область (domain knowledge) та творчого підходу для **створення нових ознак** зі "сирих" даних або **трансформації існуючих ознак** таким чином, щоб вони стали більш інформативними та корисними для алгоритмів машинного навчання. Це часто вважається одним із найважливіших етапів, що найбільше впливає на якість моделі.

* **Чому це важливо?** Алгоритми ML навчаються на ознаках, які ми їм надаємо. Якість цих ознак безпосередньо визначає якість моделі. Принцип "Сміття на вході – сміття на виході" (Garbage In, Garbage Out) тут працює на 100%. Добре сконструйовані ознаки допомагають моделі легше виявити закономірності.

* **Поширені техніки:**
    * **Обробка пропущених значень:**
        * **Імпутація:** Заміна пропусків середнім, медіаною, модою або більш складними методами (напр., прогнозування пропущеного значення іншою моделлю).
        * **Створення індикатора:** Додавання бінарної ознаки, що вказує, чи було значення пропущене (іноді сам факт пропуску є інформативним).
    * **Обробка категоріальних ознак:**
        * **One-Hot Encoding:** Створення окремої бінарної (0/1) колонки для кожної категорії. Підходить для лінійних моделей, але може створювати багато колонок для ознак з великою кількістю категорій.
        * **Label Encoding:** Присвоєння унікального числового коду кожній категорії (напр., "Львів": 0, "Київ": 1, "Одеса": 2). Слід використовувати обережно з не-деревовидними моделями, бо може внести неіснуючий порядок.
        * **Target Encoding:** Кодування категорії середнім значенням цільової змінної для цієї категорії (обчислюється обережно, щоб уникнути витоку даних з валідаційної/тестової вибірки).
    * **Обробка числових ознак:**
        * **Бінінг (Binning) / Дискретизація:** Групування неперервних значень у дискретні інтервали (напр., вікові групи). Допомагає лінійним моделям захоплювати нелінійності.
        * **Математичні трансформації:** Застосування функцій (логарифм, квадратний корінь) для нормалізації розподілу ознаки або стабілізації дисперсії.
        * **Масштабування / Нормалізація:** Приведення ознак до одного діапазону (напр., [0, 1] за допомогою Min-Max Scaling) або до нульового середнього та одиничної дисперсії (Standard Scaling). Критично важливо для KNN, SVM, нейронних мереж.
    * **Створення нових ознак:**
        * **Взаємодії ознак (Interaction Features):** Комбінування двох або більше ознак (напр., добуток, частка). Наприклад, `ціна_за_метр = ціна_квартири / площа`.
        * **Поліноміальні ознаки:** Створення ознак вищого порядку ($x^2$, $x^3$, $x_1 \cdot x_2$) для моделювання нелінійних залежностей лінійними моделями.
        * **Ознаки на основі знань про домен:** Використання експертних знань. Наприклад, при прогнозуванні попиту на таксі у Львові можна створити ознаки: "день тижня", "чи є свято/фестиваль", "відстань до центру міста", "погодні умови".

Інженерія ознак – це ітеративний процес, що вимагає експериментів та розуміння даних і задачі.

---

**Відбір ознак (Feature Selection)**

* **Що це?** Процес вибору **найбільш релевантної підмножини** ознак із початкового набору для використання при побудові моделі.

* **Навіщо це потрібно?**
    * **Покращення якості моделі:** Видалення нерелевантних ("шумових") або надлишкових (сильно корельованих) ознак може зменшити перенавчання та покращити генералізацію.
    * **Зменшення обчислювальних витрат:** Менше ознак – швидше навчання та прогнозування.
    * **Покращення інтерпретованості:** Модель з меншою кількістю ознак легше зрозуміти.
    * **Уникнення "прокляття розмірності".**

* **Основні підходи (оглядово):**
    1.  **Методи фільтрації (Filter Methods):** Ознаки оцінюються та відбираються **до** навчання моделі на основі їхніх статистичних властивостей (напр., кореляції з цільовою змінною, взаємної інформації, дисперсії). Швидкі, але не враховують взаємодію ознак у контексті конкретної моделі.
    2.  **Методи обгортки (Wrapper Methods):** Використовують певну модель машинного навчання для оцінки корисності різних **підмножин** ознак. Перебирають різні комбінації ознак, навчають і оцінюють модель для кожної. Точніші, але значно більш обчислювально дорогі (напр., Рекурсивне усунення ознак - RFE).
    3.  **Вбудовані методи (Embedded Methods):** Відбір ознак відбувається **під час** навчання самої моделі. Алгоритм має вбудований механізм для оцінки та відбору ознак.
        * *Приклади:* L1-регуляризація (Lasso) у лінійних моделях, яка "зануляє" ваги неважливих ознак; оцінка важливості ознак у Деревах рішень та Випадкових лісах.

Відбір ознак часто йде пліч-о-пліч з інженерією ознак.

---

**Крос-валідація (Cross-Validation)**

* **Проблема простого розділення Train/Validation/Test:** Коли ми один раз розділили дані, оцінка якості на валідаційній вибірці може сильно залежати від того, які саме дані випадково потрапили у цю вибірку. Особливо це критично для невеликих наборів даних. Результат може бути не дуже надійним.

* **Ідея крос-валідації:** Отримати більш **стабільну та надійну оцінку** здатності моделі до генералізації шляхом багаторазового розділення даних на навчальну та валідаційну частини та усереднення результатів.

* **K-блочна крос-валідація (K-Fold Cross-Validation):** Найпоширеніший метод.
    1.  Перемішати вихідний навчальний набір даних.
    2.  Розділити його на $K$ рівних частин ("блоків" або "фолдів", fold). Типові значення $K=5$ або $K=10$.
    3.  **Повторити $K$ разів:**
        * Вибрати один блок як **валідаційний** на цій ітерації.
        * Решту $K-1$ блоків використати як **навчальний** набір.
        * Навчити модель на навчальному наборі.
        * Оцінити якість навченої моделі на валідаційному блоці (за обраною метрикою).
    4.  **Усереднити результати:** Обчислити середнє значення $K$ отриманих оцінок якості. Це середнє значення і є оцінкою за крос-валідацією – більш надійним показником продуктивності моделі.

* **Переваги:** Дає більш об'єктивну оцінку якості моделі, ефективніше використовує дані (кожен приклад побуває у валідаційній вибірці рівно один раз).
* **Використання:** Головним чином для **оцінки та порівняння** різних моделей або для **налаштування гіперпараметрів**. Фінальна модель зазвичай навчається на *всіх* даних, що були доступні до розділення на тест (тобто на об'єднаних K блоках). **Тестова вибірка залишається недоторканою** до самого кінця!

---

**Налаштування гіперпараметрів (Hyperparameter Tuning)**

* **Що це?** **Гіперпараметри** – це "налаштування" самого алгоритму машинного навчання, які ми задаємо **до** початку тренування (вони не вивчаються з даних). Наприклад: $k$ у KNN, $C$ та $\gamma$ в SVM, швидкість навчання $\alpha$ у градієнтному спуску, кількість дерев у Випадковому лісі, глибина дерева, параметр регуляризації $\lambda$. Значення гіперпараметрів сильно впливають на якість моделі. **Налаштування гіперпараметрів** – це процес пошуку їх оптимальних значень для конкретної задачі та даних.

* **Стратегії пошуку:**
    1.  **Ручний підбір:** Базується на досвіді, інтуїції, експериментах. Часто неефективний і суб'єктивний.
    2.  **Пошук по сітці (Grid Search):**
        * Визначити набір можливих значень для кожного гіперпараметра, який ми хочемо налаштувати (напр., $k \in \{3, 5, 7, 9\}$, $C \in \{0.1, 1, 10, 100\}$).
        * Перебрати **всі можливі комбінації** значень гіперпараметрів з цієї сітки.
        * Для кожної комбінації навчити модель та оцінити її якість за допомогою **крос-валідації**.
        * Вибрати комбінацію гіперпараметрів, яка дала найкращий середній результат на крос-валідації.
        * *Недолік:* Дуже ресурсоємний, якщо гіперпараметрів багато або діапазони значень великі (кількість комбінацій швидко зростає).
    3.  **Випадковий пошук (Random Search):**
        * Замість того, щоб перебирати всі комбінації, визначити **діапазон** або **розподіл** для кожного гіперпараметра.
        * Випадковим чином вибрати певну кількість (напр., 50 або 100) комбінацій гіперпараметрів з цих діапазонів/розподілів.
        * Для кожної випадкової комбінації навчити модель та оцінити її якість за допомогою **крос-валідації**.
        * Вибрати комбінацію, що дала найкращий результат.
        * *Перевага:* Часто знаходить дуже добрі (або навіть кращі) результати значно швидше, ніж Grid Search, особливо коли деякі гіперпараметри важливіші за інші. Зазвичай є кращим вибором.
    4.  **Більш просунуті методи:** Баєсівська оптимізація, генетичні алгоритми (прагнуть знайти оптимум ще ефективніше).

* **Важливо:** Налаштування гіперпараметрів завжди проводиться з використанням **валідаційної вибірки** або **крос-валідації**, щоб уникнути перенавчання на тестовій вибірці.

---

**Підсумки**

* Побудова ефективних моделей ML – це не лише вибір алгоритму, а й ретельна робота з даними та налаштуваннями.
* **Інженерія ознак** дозволяє створити інформативні входи для моделі.
* **Відбір ознак** допомагає видалити шум та надлишковість.
* **Крос-валідація** надає надійний спосіб оцінки якості моделі.
* **Налаштування гіперпараметрів** (за допомогою Grid Search або Random Search з крос-валідацією) дозволяє знайти оптимальні налаштування для обраного алгоритму.

Опанування цих практичних аспектів є ключем до перетворення теоретичних знань на реальні, працюючі системи штучного інтелекту, здатні вирішувати складні задачі тут, в Україні, та у всьому світі.

**Наступні кроки**

* Подумайте, які ознаки ви могли б створити для задачі прогнозування успішності студента, маючи дані про його відвідуваність, оцінки за домашні завдання та активність на лекціях?
* Чому оцінка моделі лише на одній валідаційній вибірці може бути недостатньо надійною?
* Тепер, озброївшись цими практичними знаннями, ми можемо повернутися до глибокого навчання і подивитись, як ці принципи застосовуються при тренуванні складних нейронних мереж.

---

Дякую за увагу! Не забуваємо про вподобайку, поширення та чесний відгук чи запитання в коментарях, до зустрічі!