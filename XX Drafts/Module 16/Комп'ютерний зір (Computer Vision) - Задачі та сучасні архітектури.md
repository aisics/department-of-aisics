**Лекція 16: Комп'ютерний зір (Computer Vision) - Задачі та сучасні архітектури**

**Мета лекції:** Розширити уявлення про задачі комп'ютерного зору (КЗ) за межі простої класифікації. Ознайомити з ключовими архітектурними інноваціями в згорткових нейронних мережах (ResNet, Inception), які дозволили створювати значно глибші та ефективніші моделі. Розглянути основні підходи до вирішення задачі детекції об'єктів (YOLO, Faster R-CNN).

---

Доброго дня! На попередніх лекціях ми вивчили будівельні блоки згорткових нейронних мереж (CNN) та розглянули деякі ранні, але впливові архітектури, такі як LeNet, AlexNet та VGG. Ми побачили, як CNN ефективно обробляють зображення, вивчаючи ієрархію візуальних ознак.

Сьогодні ми заглибимося у світ **комп'ютерного зору (Computer Vision - CV)** – галузі штучного інтелекту, що прагне навчити машини "бачити" та інтерпретувати візуальну інформацію так, як це робить людина. Ми:

1.  Розглянемо **основні задачі**, які вирішує комп'ютерний зір.
2.  Познайомимося з **сучасними архітектурами CNN**, що дозволили досягти значного прогресу.
3.  Розглянемо **основи детекції об'єктів** – важливої задачі КЗ.

---

**Основні задачі комп'ютерного зору (КЗ)**

Хоча класифікація є фундаментальною, комп'ютерний зір вирішує набагато ширше коло завдань, що вимагають більш детального розуміння візуальної сцени:

1.  **Класифікація зображень (Image Classification):**
    * **Завдання:** Присвоїти зображенню одну мітку з набору можливих класів.
    * **Вхід:** Зображення.
    * **Вихід:** Мітка класу (напр., "кіт", "собака", "автомобіль").
    * *Приклад:* Визначити породу собаки на фотографії.

2.  **Класифікація з локалізацією (Classification with Localization):**
    * **Завдання:** Не лише класифікувати основний об'єкт на зображенні, але й вказати його **місцезнаходження** за допомогою обмежувальної рамки (bounding box).
    * **Вхід:** Зображення.
    * **Вихід:** Мітка класу + координати рамки (напр., "кіт", [x_min, y_min, x_max, y_max]).
    * *Приклад:* Визначити, що на фото кіт, і обвести його рамкою.

3.  **Детекція об'єктів (Object Detection):**
    * **Завдання:** Знайти **всі** об'єкти певних класів на зображенні, локалізувати їх за допомогою рамок та класифікувати кожен знайдений об'єкт.
    * **Вхід:** Зображення.
    * **Вихід:** Список об'єктів, де для кожного вказано клас та координати рамки (напр., [("автомобіль", рамка1), ("людина", рамка2), ("автомобіль", рамка3)]).
    * *Приклад:* Знайти та обвести всіх пішоходів та автомобілі на зображенні міської вулиці. Це значно складніше за локалізацію одного об'єкта.

4.  **Сегментація зображень (Image Segmentation):**
    * **Завдання:** Класифікувати **кожен піксель** зображення, відносячи його до певного класу. Дає найдетальніше розуміння сцени.
    * **Типи:**
        * **Семантична сегментація (Semantic Segmentation):** Кожен піксель отримує мітку класу (напр., "дорога", "небо", "будівля", "автомобіль"). Не розрізняє окремі екземпляри одного класу (всі автомобілі будуть одного кольору).
        * **Сегментація екземплярів (Instance Segmentation):** Кожен піксель отримує мітку класу, *але* різні екземпляри одного класу розрізняються (напр., кожен автомобіль матиме свій унікальний ідентифікатор або колір).
    * *Приклад:* Точно виділити межі всіх об'єктів на зображенні (напр., для медичної діагностики або автономного водіння).

Ці задачі вимагають все більш складних моделей та архітектур для їх вирішення.

---

**Сучасні архітектури CNN (ResNet, Inception)**

Після успіху AlexNet та VGG дослідники зіткнулися з проблемою: просте додавання шарів (збільшення глибини) не завжди покращувало результат, а іноді навіть погіршувало його через **зникаючі градієнти** та так звану **"проблему деградації"**. Дві архітектури запропонували революційні рішення:

1.  **ResNet (Residual Networks) (Хе та ін., 2015):**
    * **Контекст:** Дозволила тренувати **надзвичайно глибокі** нейронні мережі (сотні, навіть тисячі шарів) і досягла перемоги на ILSVRC 2015.
    * **Ключова ідея: Залишкові блоки (Residual Blocks) з пропускними з'єднаннями (Skip Connections).** Замість того, щоб кілька шарів намагалися вивчити безпосередньо потрібне перетворення $H(x)$ з входу $x$, вони вчаться моделювати **залишкову функцію** $F(x) = H(x) - x$. Тоді вихід блоку обчислюється як $H(x) = F(x) + x$.
    * **Як це працює:** Вхід $x$ блоку додається безпосередньо до виходу $F(x)$ цього блоку через "пропускне з'єднання", яке йде "в обхід" шарів блоку.
    * **Переваги:**
        * **Полегшує навчання:** Якщо оптимальним перетворенням для блоку є просто тотожне відображення (нічого не змінювати), то мережі легко навчити $F(x) \approx 0$. Без skip-connection навчити шари ідеально відтворювати вхід набагато складніше.
        * **Покращує потік градієнтів:** Градієнти можуть легше проходити назад через skip-connection, що значно **зменшує проблему зникаючих градієнтів** і дозволяє тренувати набагато глибші мережі.
    * **Вплив:** ResNet стала фундаментальною архітектурою, і концепція skip-connection використовується у багатьох сучасних моделях.

2.  **Inception (GoogLeNet) (Сегеді та ін., 2014):**
    * **Контекст:** Переможець ILSVRC 2014 (разом з VGG), що фокусувався на **обчислювальній ефективності** та **ширині** мережі.
    * **Ключова ідея: Модуль Inception.** Замість простого послідовного з'єднання шарів, модуль Inception виконує кілька **згорткових операцій з різними розмірами фільтрів (напр., 1x1, 3x3, 5x5) та операцію пулінгу паралельно** над одним і тим же входом. Потім результати (карти ознак) цих паралельних гілок **конкатенуються (об'єднуються) за глибиною**.
    * **Переваги:**
        * **Виявлення ознак на різних масштабах:** Дозволяє мережі одночасно аналізувати інформацію на різних рівнях деталізації в межах одного шару.
        * **Обчислювальна ефективність:** Широке використання **згорток 1x1** перед "дорожчими" згортками 3x3 та 5x5 для **зменшення розмірності** (кількості каналів), що значно скорочує кількість обчислень.
    * **Вплив:** Показала переваги "ширших" мереж та ефективного дизайну модулів. Існує кілька версій Inception (v2, v3, v4, Inception-ResNet), що вдосконалювали цю ідею.

* **Інші напрямки:** Розвиток архітектур триває. З'явилися **DenseNet** (ще сильніше використання skip-connections), **MobileNet**, **EfficientNet** (фокус на ефективності для мобільних пристроїв), а останнім часом – **Vision Transformer (ViT)**, що застосовує архітектуру Transformer (спочатку розроблену для NLP) до задач комп'ютерного зору.

---

**Обгорткові мережі для детекції об'єктів (Основи YOLO, Faster R-CNN)**

Як CNN вирішують складнішу задачу детекції об'єктів (знаходження рамок та класів)? Існують два основні підходи:

1.  **Двостадійні детектори (Two-Stage Detectors):**
    * **Представники:** Сімейство R-CNN (R-CNN, Fast R-CNN, **Faster R-CNN**).
    * **Принцип роботи:**
        1.  **Генерація пропозицій регіонів (Region Proposal):** На першому етапі спеціальний механізм (наприклад, Selective Search або Region Proposal Network - RPN у Faster R-CNN) генерує набір потенційних регіонів зображення, де *можуть* знаходитись об'єкти.
        2.  **Класифікація та регресія рамок:** На другому етапі для кожного запропонованого регіону за допомогою CNN витягуються ознаки, і потім окремі класифікатори визначають клас об'єкта в регіоні, а регресори уточнюють координати обмежувальної рамки.
    * **Переваги:** Зазвичай досягають високої точності детекції.
    * **Недоліки:** Можуть бути повільнішими через двостадійний процес.

2.  **Одностадійні детектори (One-Stage Detectors):**
    * **Представники:** **YOLO (You Only Look Once)**, SSD (Single Shot MultiBox Detector).
    * **Принцип роботи:** Розглядають детекцію як єдину задачу регресії та класифікації, що виконується **за один прохід** мережі. Немає окремого етапу генерації пропозицій регіонів.
    * **YOLO:** Ділить зображення на сітку. Для кожної комірки сітки мережа одночасно прогнозує:
        * Декілька можливих обмежувальних рамок (bounding boxes).
        * Оцінку впевненості (confidence score) для кожної рамки (наскільки ймовірно, що там є об'єкт).
        * Ймовірності належності до класів для об'єкта в цій комірці.
    * **SSD:** Використовує ознаки з різних рівнів (шарів) базової CNN для детекції об'єктів різного розміру.
    * **Переваги:** **Значно швидші**, часто здатні працювати в режимі реального часу.
    * **Недоліки:** Історично могли поступатися двостадійним детекторам у точності, особливо для маленьких об'єктів (хоча сучасні версії значно покращились).

Вибір між двостадійними та одностадійними детекторами залежить від пріоритетів: максимальна точність чи максимальна швидкість.

---

**Підсумки**

* Комп'ютерний зір вирішує різноманітні задачі: **класифікацію, локалізацію, детекцію об'єктів, семантичну та інстансну сегментацію**.
* Сучасні архітектури CNN, такі як **ResNet** (з skip-connections для тренування дуже глибоких мереж) та **Inception/GoogLeNet** (з паралельними фільтрами та 1x1 згортками для ефективності та багатомасштабності), значно просунули можливості КЗ.
* Для **детекції об'єктів** використовуються спеціалізовані архітектури, що поділяються на **двостадійні** (як **Faster R-CNN** – точніші, повільніші) та **одностадійні** (як **YOLO**, SSD – швидші).
* **Трансферне навчання** залишається ключовим підходом для практичного застосування цих потужних моделей.

Комп'ютерний зір – це динамічна галузь, де постійно з'являються нові архітектури та підходи, що базуються на фундаментальних принципах CNN, які ми розглянули. Ці технології вже змінюють багато аспектів нашого життя, від медицини до транспорту, і їхній вплив буде лише зростати.

**Наступні кроки**

* Пошукайте відео-демонстрації роботи YOLO або інших детекторів об'єктів в реальному часі.
* Подумайте, як skip-connections у ResNet допомагають градієнтам поширюватися назад у глибоких мережах.
* На наступній лекції ми можемо перейти до іншої важливої теми – обробки природної мови (NLP) та моделей, що використовуються для цього, наприклад, Transformer.

---

Дякую за увагу! Не забуваємо про вподобайку, поширення та чесний відгук чи запитання в коментарях, до зустрічі!