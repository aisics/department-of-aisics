---
title: "Functions and Derivatives - How AI Learns"
description: "What are functions, derivatives, and gradients. How neural networks find optimal solutions through gradient descent"
author: "Department of AIsics"
date: 2025-07-25
readingTime: 35
tags: ["functions", "derivatives", "gradient", "optimization", "learning", "mathematics"]
featured: true
difficulty: "intermediate"
category: "Basics"
prerequisites: ["vectors-in-ai", "matrixes-in-ai"]
relatedArticles: ["matrix-transformations"]
---

import PlotlyFunction from '../../../../components/PlotlyFunction.astro';
import MathPlotSimple from '../../../../components/MathPlotSimple.astro';
import VisualDisplay from '../../../../components/VisualDisplay.astro';
import TangentLineDemo from '../../../../components/TangentLineDemo.astro';
import CatJumpAnimation from '../../../../components/CatJumpAnimation.astro';
import DartAnimation from '../../../../components/DartAnimation.astro';

# Lecture 4: Functions and Derivatives – How AI Finds the Best Solutions 📈

In previous lectures, we learned to work with data (vectors and matrices) and transform them. But how does AI know which transformations are needed? How does a neural network "learn" to recognize cats or predict weather? The answer lies in functions and their derivatives!

<div style="background: #fef3c7; border: 2px solid #f59e0b; border-radius: 8px; padding: 1rem; margin: 1rem 0;">
<strong>⚠️ Educational Simplification:</strong><br/>
This lecture simplifies mathematical concepts for better understanding. We focus on intuition and practical examples rather than rigorous proofs. Visualizations may be schematic for clarity.
</div>

## Functions – Mathematical "Transformers" 🔄

### What is a Function?

**A function** is a rule that assigns exactly one output value to each input value (or set of values).

Think of a function as a **machine** that:
- 📥 Takes input data
- ⚙️ Processes it according to a rule
- 📤 Produces a result

### Example 1: Coffee Machine ☕

Imagine a function "making coffee":

$$
f(\text{coffee\_amount}) = \text{drink\_strength}
$$

More specifically:
$$
f(x) = 2x + 1
$$

Where:
- $x$ – grams of coffee
- $f(x)$ – drink strength (arbitrary units)

**Calculations:**
- $f(5) = 2 \cdot 5 + 1 = 11$ (5g coffee → strength 11)
- $f(10) = 2 \cdot 10 + 1 = 21$ (10g coffee → strength 21)
- $f(15) = 2 \cdot 15 + 1 = 31$ (15g coffee → strength 31)

**Interactive Visualization:**

<MathPlotSimple
  expression="2 * x + 1"
  name="f(x) = 2x + 1"
  title="Coffee Strength Function"
  xRange={[0, 20]}
  yRange={[0, 45]}
  color="#8B4513"
  xLabel="Amount of coffee (grams)"
  yLabel="Drink strength (arbitrary units)"
/>

### Example 2: Robot Cat Error Function 🤖🐱

Our robot cat is trying to jump onto a shelf. The error function:

$$
\text{Error}(v) = (v - 5)^2
$$

Where:
- $v$ – jump velocity (m/s)
- 5 m/s – ideal velocity
- Error – how far from the target the cat landed

**Error Visualization:**

<VisualDisplay type="chart">
{`
Velocity:  3      4      5      6      7
Error:     4      1      0      1      4
Result:    😿    😐    😸    😐    😿
`}
</VisualDisplay>

We can see that:
- At $v = 5$: error = 0 (perfect! 😸)
- At $v < 5$: undershoot (😿)
- At $v > 5$: overshoot (😿)

**Interactive Error Function:**

<MathPlotSimple
  expression="Math.pow(x - 5, 2)"
  name="Error(v) = (v - 5)²"
  title="Robot Cat Jump Error Function"
  xRange={[0, 10]}
  yRange={[0, 30]}
  color="#FF6B6B"
  xLabel="Jump velocity (m/s)"
  yLabel="Error (distance from target)"
/>

### Functions of Multiple Variables 📊

In real AI, functions depend on many parameters.

**Example: Apartment Price**

$$
\text{Price} = f(\text{area}, \text{rooms}, \text{floor}, \text{district})
$$

Simplified model:
$$
f(x_1, x_2, x_3) = 1000x_1 + 50000x_2 - 5000x_3 + 200000
$$

Where:
- $x_1$ – area (m²)
- $x_2$ – number of rooms
- $x_3$ – floor
- 200000 – base price

**Sample calculation:**
- Area: 60 m²
- Rooms: 2
- Floor: 5

$$
f(60, 2, 5) = 1000 \cdot 60 + 50000 \cdot 2 - 5000 \cdot 5 + 200000
$$
$$
= 60000 + 100000 - 25000 + 200000 = 335000 \text{ UAH}
$$

## Derivatives – Rate of Change 🏃‍♂️

### Intuitive Understanding

**The derivative** shows how quickly a function changes as its input changes.

### Example: Car Speed 🚗

If a car's position is described by:
$$
s(t) = 5t^2
$$

Where $s$ is distance (m), $t$ is time (s).

**Speed** is the derivative of position with respect to time:
$$
v(t) = s'(t) = 10t
$$

**What this means:**
- At $t = 1$: speed = 10 m/s
- At $t = 2$: speed = 20 m/s
- At $t = 3$: speed = 30 m/s

The car is accelerating!

### Geometric Meaning of Derivative 📐

The derivative at a point = slope of the tangent line to the function graph at that point.

**Visualization for** $f(x) = x^2$:

<TangentLineDemo
  title="Function f(x) = x² and Tangent Lines"
  xRange={[-3, 3]}
  yRange={[-1, 9]}
  height={400}
/>

- At point $x = 0$: $f'(0) = 0$ (horizontal tangent)
- At point $x = 1$: $f'(1) = 2$ (tangent slopes upward)
- At point $x = 2$: $f'(2) = 4$ (tangent slopes upward more steeply)

**Interactive Visualization of f(x) = x² and its Derivative:**

<PlotlyFunction
  type="2d"
  title="Function f(x) = x² and its Derivative f'(x) = 2x"
  xLabel="x"
  yLabel="y"
  xRange={[-3, 3]}
  yRange={[-2, 10]}
  functions={JSON.stringify([
    {
      name: "f(x) = x²",
      expression: "x * x",
      color: "#3498DB"
    },
    {
      name: "f'(x) = 2x",
      expression: "2 * x",
      color: "#E74C3C"
    }
  ])}
/>

### Differentiation Rules 📝

**Basic rules:**

1. **Constant:** $\frac{d}{dx}(c) = 0$
2. **Power function:** $\frac{d}{dx}(x^n) = nx^{n-1}$
3. **Sum:** $\frac{d}{dx}[f(x) + g(x)] = f'(x) + g'(x)$
4. **Constant multiple:** $\frac{d}{dx}[c \cdot f(x)] = c \cdot f'(x)$

**Application example:**

For the cat error function:
$$
\text{Error}(v) = (v - 5)^2 = v^2 - 10v + 25
$$

Derivative:
$$
\text{Error}'(v) = 2v - 10
$$

**What this means:**
- When $v < 5$: derivative is negative → error decreases as velocity increases
- When $v > 5$: derivative is positive → error increases as velocity increases
- When $v = 5$: derivative = 0 → minimum error!

**Visualization of Error Function and its Derivative:**

<PlotlyFunction
  type="2d"
  title="Error Function and its Derivative"
  xLabel="Velocity (m/s)"
  yLabel="Value"
  xRange={[0, 10]}
  yRange={[-15, 30]}
  functions={JSON.stringify([
    {
      name: "Error(v) = (v - 5)²",
      expression: "Math.pow(x - 5, 2)",
      color: "#FF6B6B"
    },
    {
      name: "Error'(v) = 2(v - 5)",
      expression: "2 * (x - 5)",
      color: "#4ECDC4"
    }
  ])}
/>

## Gradient – Compass in Parameter Space 🧭

### Partial Derivatives

For functions of multiple variables, we compute **partial derivatives** – derivatives with respect to each variable separately.

**Example: Mountain Height Function**
$$
h(x, y) = -(x^2 + y^2)
$$

This is an inverted paraboloid – like a mountain with peak at (0, 0).

Partial derivatives:
$$
\frac{\partial h}{\partial x} = -2x
$$
$$
\frac{\partial h}{\partial y} = -2y
$$

### Gradient – Vector of All Partial Derivatives

**The gradient** is a vector composed of all partial derivatives:

$$
\nabla h = \begin{pmatrix} \frac{\partial h}{\partial x} \\ \frac{\partial h}{\partial y} \end{pmatrix} = \begin{pmatrix} -2x \\ -2y \end{pmatrix}
$$

**Key property:** The gradient points in the direction of steepest ascent!

### Gradient Visualization 🏔️

Imagine standing on a mountain slope. The gradient always points in the direction of the steepest climb:

**Interactive 3D Mountain Visualization:**

<PlotlyFunction
  type="3d"
  title="Mountain Height Function: h(x,y) = -(x² + y²)"
  xLabel="x"
  yLabel="y"
  zLabel="h(x,y)"
  xRange={[-3, 3]}
  yRange={[-3, 3]}
  functions={JSON.stringify([
    {
      name: "h(x,y) = -(x² + y²)",
      expression: "-(x*x + y*y)",
      colorscale: "Earth"
    }
  ])}
/>

- **Gradient** points in the direction of steepest ascent
- **Negative gradient** points in the direction of steepest descent

**Calculation example:**

At point $(1, 2)$:
$$
\nabla h(1, 2) = \begin{pmatrix} -2 \cdot 1 \\ -2 \cdot 2 \end{pmatrix} = \begin{pmatrix} -2 \\ -4 \end{pmatrix}
$$

This means:
- The function decreases faster in the $y$ direction (component -4)
- To climb the mountain, move in direction $(2, 4)$

## Gradient Descent – AI Learning Algorithm 🎯

### Basic Idea

**Gradient descent** is a method of finding a function's minimum by moving in the direction opposite to the gradient.

**Algorithm:**
1. Start at a random point
2. Calculate the gradient at this point
3. Take a step in the negative gradient direction
4. Repeat until reaching the minimum

### Parameter Update Formula

$$
\theta_{\text{new}} = \theta_{\text{old}} - \alpha \cdot \nabla f(\theta_{\text{old}})
$$

Where:
- $\theta$ – parameters (weights, biases, etc.)
- $\alpha$ – learning rate
- $\nabla f$ – gradient of the loss function

### Example: Teaching the Robot Cat 🤖

Let's return to our cat learning to jump:

**Error function:** $E(v) = (v - 5)^2$

**Derivative:** $E'(v) = 2(v - 5)$

**Learning process** with $\alpha = 0.1$:

1. **Attempt 1:** $v_0 = 2$ m/s
   - Error: $E(2) = (2-5)^2 = 9$
   - Gradient: $E'(2) = 2(2-5) = -6$
   - Update: $v_1 = 2 - 0.1 \cdot (-6) = 2.6$

2. **Attempt 2:** $v_1 = 2.6$ m/s
   - Error: $E(2.6) = (2.6-5)^2 = 5.76$
   - Gradient: $E'(2.6) = 2(2.6-5) = -4.8$
   - Update: $v_2 = 2.6 - 0.1 \cdot (-4.8) = 3.08$

3. **Attempt 3:** $v_2 = 3.08$ m/s
   - Error: $E(3.08) = (3.08-5)^2 = 3.69$
   - And so on...

**Progress Visualization:**

<VisualDisplay type="progress">
{`Attempt:   1     2     3     4     5    ...   10
Velocity:  2.0   2.6   3.08  3.46  3.77  ...  4.65
Error:     9.0   5.76  3.69  2.36  1.51  ...  0.12
Cat:       😿    😟    😐    🙂    😊    ...  😸`}
</VisualDisplay>

**🎮 Interactive Learning Demonstration:**

Now watch this work in real time! Click "Start Learning" and observe how the robot cat learns to jump correctly:

<CatJumpAnimation targetHeight={5} iterations={10} />

### Choosing the Learning Rate ⚡

The learning rate $\alpha$ is critically important:

**Too small** ($\alpha = 0.01$):

<VisualDisplay type="comparison">
{`Iteration: 1    10    50    100   200
Error:     9.0  8.1   5.2   3.3   1.3
           🐌 too slow...`}
</VisualDisplay>

💭 **Imagine:** You're walking to the store in tiny 1cm steps. Yes, you'll get there, but when? In an hour you'll only travel 36 meters! Your robot cat is similarly "crawling" to the goal - it will drain its battery before learning to jump. In the real world, this means days or weeks of training instead of hours.

**Optimal** ($\alpha = 0.1$):

<VisualDisplay type="comparison">
{`Iteration: 1    5     10    15    20
Error:     9.0  1.5   0.24  0.04  0.006
           ✅ converges quickly!`}
</VisualDisplay>

🎯 **Perfect balance:** Like an experienced driver on the road - not too slow (holding up others), not too fast (dangerous), but at just the right speed! The cat makes smart steps: large at first to quickly approach, then smaller for precise landing. It's like archery - you need to find the ideal draw strength: too weak - arrow won't reach, too strong - overshoots the target.

**Too large** ($\alpha = 1.5$):

<VisualDisplay type="comparison">
{`Iteration: 1    2     3     4     5
Error:     9.0  36    144   576   2304
           💥 diverges!`}
</VisualDisplay>

🚀 **Catastrophe!** It's like trying to catch a butterfly with a sledgehammer - instead of getting closer to the goal, you destroy it! The robot cat jumps so hard it flies across the room, bounces off the wall and flies back. With each attempt it flies further away. In neural networks this leads to "gradient explosion" - numbers become so large the computer just throws an error.

## Chain Rule – Foundation of Deep Learning 🔗

### What is the Chain Rule?

**The chain rule** allows computing derivatives of composite functions.

If $y = f(g(x))$, then:
$$
\frac{dy}{dx} = \frac{dy}{dg} \cdot \frac{dg}{dx}
$$

### Example: Making Perfect Pizza 🍕

Imagine the process:
1. **Oven temperature** → **Baking time** → **Pizza quality**

Mathematically:
- $t$ – oven temperature (°C)
- $m = g(t) = \frac{600}{t}$ – baking time (min)
- $q = f(m) = -(m - 15)^2 + 100$ – pizza quality (points)

**Why exactly 15 minutes?** In the quality formula we see $(m - 15)^2$ - this means best quality (100 points) is achieved when $m = 15$ minutes. Baking less or more decreases quality!

**Composition:** $q(t) = f(g(t)) = -\left(\frac{600}{t} - 15\right)^2 + 100$

**How does temperature affect quality?**

Using the chain rule:
$$
\frac{dq}{dt} = \frac{dq}{dm} \cdot \frac{dm}{dt}
$$

Calculate:
- $\frac{dq}{dm} = -2(m - 15)$
- $\frac{dm}{dt} = -\frac{600}{t^2}$

Therefore:
$$
\frac{dq}{dt} = -2\left(\frac{600}{t} - 15\right) \cdot \left(-\frac{600}{t^2}\right)
$$

**🤔 What does this mean in simple terms?**

Let's break down specific examples:

1. **At 200°C:** 
   - Baking time: 600/200 = 3 minutes (too fast!)
   - Quality: -(3-15)² + 100 = -144 + 100 = **-44 points** 🔥
   - Result: Burned on top, raw inside!

2. **At 300°C:**
   - Baking time: 600/300 = 2 minutes (still fast)
   - Quality: -(2-15)² + 100 = -169 + 100 = **-69 points** 💀
   - Result: Charcoal instead of pizza!

3. **At 40°C:**
   - Baking time: 600/40 = 15 minutes (perfect!)
   - Quality: -(15-15)² + 100 = 0 + 100 = **100 points** 🍕✨
   - Result: Golden crust, melted cheese!

4. **At 30°C:**
   - Baking time: 600/30 = 20 minutes (too long)
   - Quality: -(20-15)² + 100 = -25 + 100 = **75 points** 😐
   - Result: Dried out, hard as a rock

**Conclusion:** The chain rule shows how temperature change (through time change) affects quality. At 40°C we achieve the ideal 15 minutes of baking!

### Application in Neural Networks 🧠

In a neural network we have many layers:

<VisualDisplay type="diagram">
{`Input → Layer 1 → Layer 2 → ... → Layer N → Output
 x   →  h₁(x)   → h₂(h₁)  → ... → hₙ(...) → y`}
</VisualDisplay>

To train the network, we need to know how each weight affects the error. The chain rule allows "passing" the gradient back through all layers!

## Practical Example: Teaching AI to Play Darts 🎯

### Problem Setup

AI controls the force ($f$) and angle ($\theta$) of dart throws. Goal – hit the bullseye.

**🎮 Imagine the situation:**
- Robot stands 3 meters from the dartboard
- Bullseye is at coordinates (3, 1.7) - at height 1.7m (standard height)
- Robot throws from height 1.5m (robot's arm)
- Robot can control:
  - **Throw velocity** ($v$): from 0 to 15 m/s
  - **Throw angle** ($\theta$): from -45° to +45° (in radians)

**Realistic flight function (with gravity!):**

Time to reach target: $t = \frac{3}{v\cos\theta}$

Dart height at impact: $h = 1.5 + v\sin\theta \cdot t - \frac{g \cdot t^2}{2}$

Where $g = 9.8$ m/s² - gravitational acceleration

**Miss function:**
$$
d(v, \theta) = |h - 1.7|
$$

**📐 What happens physically:**
- At $\theta = 0°$ (horizontal): dart immediately starts falling
- At $\theta > 0°$: dart flies in parabola up, then down
- At $\theta < 0°$: dart flies downward (dangerous!)
- The higher the velocity, the less the dart falls

**Realistic examples:**
- $v=8$ m/s, $\theta=0°$: flight time 0.375s, falls 0.69m → hits at height 0.81m (miss 0.89m) 😢
- $v=10$ m/s, $\theta=10°$: flies in arc, hits at height 1.65m (miss 0.05m) 😊
- $v=12$ m/s, $\theta=5°$: almost perfect! Hits at 1.71m (miss 0.01m) 🎯

**Loss function:**
$$
L(v, \theta) = d(v, \theta)^2
$$

**Why squared?** So larger misses are "punished" more severely. A 2cm miss gives loss 4, but a 10cm miss gives 100!

### Gradient Descent for Two Parameters

**🧮 How does the robot learn?**

The robot uses gradients to understand how to change force and angle:

**Partial derivatives (intuitively):**
- $\frac{\partial L}{\partial v}$ - "If I throw faster, will the dart hit higher or lower?"
- $\frac{\partial L}{\partial \theta}$ - "If I increase the angle upward, will this compensate for gravity?"

**Physical intuition:**
- Increasing velocity → less flight time → less fall from gravity
- Increasing angle → dart flies higher, but slower horizontally → more time to fall

**Mathematically:**
$$
\frac{\partial L}{\partial v} = 2d \cdot \frac{\partial d}{\partial v}
$$
$$
\frac{\partial L}{\partial \theta} = 2d \cdot \frac{\partial d}{\partial \theta}
$$

**🎯 Learning strategy:**
1. Throw dart with current parameters
2. Measure miss
3. Calculate which direction to change force and angle
4. Take a small step in the right direction
5. Repeat!

**Learning process:**

```python
# Initial parameters (robot starts with naive settings!)
v = 8.0      # velocity: 8 m/s (thinks it's strong, but gravity!)
θ = 0.0      # angle: 0° (throws straight, doesn't account for fall)
α = 0.1      # learning rate

# Physical constants
g = 9.8      # gravity (m/s²)
distance = 3.0  # distance to target (m)
target_height = 1.7  # bullseye height (m)
robot_height = 1.5  # throwing height (m)

# 10 learning iterations
for i in range(10):
    # Step 1: Calculate trajectory
    t = distance / (v * cos(θ))  # flight time
    h = robot_height + v * sin(θ) * t - 0.5 * g * t * t  # impact height
    miss = abs(h - target_height)  # miss distance
    
    # Step 2: Calculate gradients
    # "How will parameter changes affect height?"
    grad_v = calculate_gradient_v(v, θ)  # e.g.: -2.1 (faster = higher!)
    grad_θ = calculate_gradient_θ(v, θ)  # e.g.: +5.3 (throw upward!)
    
    # Step 3: Update parameters
    v = v - α * grad_v  # 8.0 - 0.1*(-2.1) = 8.21 (slightly faster)
    θ = θ - α * grad_θ  # 0.0 - 0.1*(5.3) = 0.053 rad (~3°)
    
    # Step 4: Result
    print(f"Attempt {i+1}: miss = {miss:.3f}m, v={v:.1f}m/s, θ={degrees(θ):.1f}°")
    
    # Physics works! Robot learned to compensate for gravity!
```

**Results visualization:**

<VisualDisplay type="progress">
{`Attempt 1: 🎯........................ (89 cm below!)
Attempt 3: 🎯.................. (42 cm below)
Attempt 5: 🎯............ (12 cm below)
Attempt 7: 🎯...... (5 cm below)
Attempt 10: 🎯.. (2 cm) Hit! 🎉`}
</VisualDisplay>

**🎮 Interactive Darts Learning Demonstration:**

Watch how the robot learns to throw darts! Click "Start Learning" and observe how gradient descent helps the robot find the right combination of velocity and angle:

<DartAnimation targetHeight={1.7} targetDistance={3.0} iterations={10} />

**🔍 What happens behind the scenes:**

**Beginning (Attempt 1):**
- Velocity: 8.0 m/s, Angle: 0° (throws straight)
- Result: dart falls 0.89m below target! 
- Gravity "ate" the height in 0.375 seconds of flight
- Gradients shout: "Throw upward! And faster!"

**Middle of learning (Attempt 5):**
- Velocity: ~10.0 m/s, Angle: ~5.5° 
- Miss reduced to 0.12m
- Robot understood: need to throw at an upward angle
- Balance between velocity and angle almost found

**Finale (Attempt 10):**
- Velocity: ~11.2 m/s, Angle: ~6.5°
- Miss only 2 cm!
- Perfect compromise: fast enough (less fall) + right angle (gravity compensation)

**💡 Key observations:**
1. Progress is fast at first (89 → 42 cm in 2 steps)
2. Then slows down (need precision)
3. Never reaches perfect 0 (always small error)
4. That's normal! In the real world 2cm is an excellent result

## Summary and Key Concepts 🎓

### What we learned:

1. **Functions** – mathematical rules for data transformation
   - Describe relationships between variables
   - Can have one or many variables

2. **Derivatives** – rate of function change
   - Show direction and steepness of change
   - Foundation for optimization

3. **Gradient** – vector of partial derivatives
   - Points in direction of steepest ascent
   - Key to learning in multidimensional space

4. **Gradient descent** – optimization algorithm
   - Move against gradient to minimum
   - Learning rate controls step size

5. **Chain rule** – derivatives of composite functions
   - Allows training deep networks
   - Foundation of backpropagation algorithm

### Why is this important for AI? 🤖

- **Learning = optimization**: AI learns by minimizing a loss function
- **Gradients show direction**: Where to move parameters for improvement
- **Chain rule scales**: Works for networks with millions of parameters
- **Automatic differentiation**: Modern frameworks compute gradients automatically

<div style="background: #e0f2fe; border: 2px solid #0284c7; border-radius: 8px; padding: 1rem; margin: 1rem 0; text-align: center;">
<strong>🎯 Main rule:</strong><br/>
The derivative shows the direction of fastest function change.<br/>
Gradient descent goes against this direction to find the minimum.<br/>
This is the foundation of all neural network learning!
</div>