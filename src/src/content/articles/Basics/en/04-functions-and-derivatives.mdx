---
title: "Functions and Derivatives - How AI Learns"
description: "What are functions, derivatives, and gradients. How neural networks find optimal solutions through gradient descent"
author: "Department of AIsics"
date: 2024-01-25
readingTime: 25
tags: ["functions", "derivatives", "gradient", "optimization", "learning", "mathematics"]
featured: true
difficulty: "intermediate"
category: "Basics"
prerequisites: ["vectors-in-ai", "matrixes-in-ai"]
relatedArticles: ["matrix-transformations"]
---

import PlotlyFunction from '../../../../components/PlotlyFunction.astro';
import MathPlotSimple from '../../../../components/MathPlotSimple.astro';

# Lecture 4: Functions and Derivatives – How AI Finds the Best Solutions 📈

In previous lectures, we learned to work with data (vectors and matrices) and transform them. But how does AI know which transformations are needed? How does a neural network "learn" to recognize cats or predict weather? The answer lies in functions and their derivatives!

<div style="background: #fef3c7; border: 2px solid #f59e0b; border-radius: 8px; padding: 1rem; margin: 1rem 0;">
<strong>⚠️ Educational Simplification:</strong><br/>
This lecture simplifies mathematical concepts for better understanding. We focus on intuition and practical examples rather than rigorous proofs. Visualizations may be schematic for clarity.
</div>

## Functions – Mathematical "Transformers" 🔄

### What is a Function?

**A function** is a rule that assigns exactly one output value to each input value (or set of values).

Think of a function as a **machine** that:
- 📥 Takes input data
- ⚙️ Processes it according to a rule
- 📤 Produces a result

### Example 1: Coffee Machine ☕

Imagine a function "making coffee":

$$
f(\text{coffee\_amount}) = \text{drink\_strength}
$$

More specifically:
$$
f(x) = 2x + 1
$$

Where:
- $x$ – grams of coffee
- $f(x)$ – drink strength (arbitrary units)

**Calculations:**
- $f(5) = 2 \cdot 5 + 1 = 11$ (5g coffee → strength 11)
- $f(10) = 2 \cdot 10 + 1 = 21$ (10g coffee → strength 21)
- $f(15) = 2 \cdot 15 + 1 = 31$ (15g coffee → strength 31)

**Interactive visualization:**

<MathPlotSimple
  expression="2 * x + 1"
  name="f(x) = 2x + 1"
  title="Coffee Strength Function"
  xRange={[0, 20]}
  yRange={[0, 45]}
  color="#8B4513"
/>

### Example 2: Robot Cat's Error Function 🤖🐱

Our robot cat is trying to jump onto a shelf. The error function:

$$
\text{Error}(v) = (v - 5)^2
$$

Where:
- $v$ – jump velocity (m/s)
- 5 m/s – ideal velocity
- Error – how far from the target the cat landed

**Error visualization:**
```
Velocity:   3    4    5    6    7
Error:      4    1    0    1    4
            😿   😐   😸   😐   😿
```

We see that:
- At $v = 5$: error = 0 (perfect! 😸)
- At $v < 5$: undershoot (😿)
- At $v > 5$: overshoot (😿)

**Interactive error function:**

<MathPlotSimple
  expression="Math.pow(x - 5, 2)"
  name="Error(v) = (v - 5)²"
  title="Robot Cat's Jump Error Function"
  xRange={[0, 10]}
  yRange={[0, 30]}
  color="#FF6B6B"
/>

### Functions of Multiple Variables 📊

In real AI, functions depend on many parameters.

**Example: Apartment Price**

$$
\text{Price} = f(\text{area}, \text{rooms}, \text{floor}, \text{district})
$$

Simplified model:
$$
f(x_1, x_2, x_3) = 1000x_1 + 50000x_2 - 5000x_3 + 200000
$$

Where:
- $x_1$ – area (m²)
- $x_2$ – number of rooms
- $x_3$ – floor
- 200000 – base price

**Sample calculation:**
- Area: 60 m²
- Rooms: 2
- Floor: 5

$$
f(60, 2, 5) = 1000 \cdot 60 + 50000 \cdot 2 - 5000 \cdot 5 + 200000
$$
$$
= 60000 + 100000 - 25000 + 200000 = 335000 \text{ USD}
$$

## Derivatives – Rate of Change 🏃‍♂️

### Intuitive Understanding

**The derivative** shows how quickly a function changes as its input changes.

### Example: Car Speed 🚗

If a car's position is described by the function:
$$
s(t) = 5t^2
$$

Where $s$ – distance (m), $t$ – time (s).

**Speed** is the derivative of position with respect to time:
$$
v(t) = s'(t) = 10t
$$

**What this means:**
- At time $t = 1$: speed = 10 m/s
- At time $t = 2$: speed = 20 m/s
- At time $t = 3$: speed = 30 m/s

The car is accelerating!

### Geometric Meaning of Derivative 📐

The derivative at a point = slope of the tangent line to the function graph at that point.

**Visualization for** $f(x) = x^2$:

```
      |     .
      |   .   (slope = 4)
  f(x)|  .
      | . (slope = 2)
      |. (slope = 0)
      +------------- x
```

- At point $x = 0$: $f'(0) = 0$ (horizontal tangent)
- At point $x = 1$: $f'(1) = 2$ (tangent goes up)
- At point $x = 2$: $f'(2) = 4$ (tangent goes up steeper)

**Interactive visualization of f(x) = x² and its derivative:**

<PlotlyFunction
  type="2d"
  title="Function f(x) = x² and its Derivative f'(x) = 2x"
  xLabel="x"
  yLabel="y"
  xRange={[-3, 3]}
  yRange={[-2, 10]}
  functions={JSON.stringify([
    {
      name: "f(x) = x²",
      expression: "x * x",
      color: "#3498DB"
    },
    {
      name: "f'(x) = 2x",
      expression: "2 * x",
      color: "#E74C3C"
    }
  ])}
/>

### Differentiation Rules 📝

**Basic rules:**

1. **Constant:** $\frac{d}{dx}(c) = 0$
2. **Power function:** $\frac{d}{dx}(x^n) = nx^{n-1}$
3. **Sum:** $\frac{d}{dx}[f(x) + g(x)] = f'(x) + g'(x)$
4. **Constant multiple:** $\frac{d}{dx}[c \cdot f(x)] = c \cdot f'(x)$

**Example application:**

For the cat's error function:
$$
\text{Error}(v) = (v - 5)^2 = v^2 - 10v + 25
$$

Derivative:
$$
\text{Error}'(v) = 2v - 10
$$

**What this means:**
- When $v < 5$: derivative is negative → error decreases as velocity increases
- When $v > 5$: derivative is positive → error increases as velocity increases
- When $v = 5$: derivative = 0 → minimum error!

**Visualizing the error function and its derivative:**

<PlotlyFunction
  type="2d"
  title="Error Function and Its Derivative"
  xLabel="Velocity (m/s)"
  yLabel="Value"
  xRange={[0, 10]}
  yRange={[-15, 30]}
  functions={JSON.stringify([
    {
      name: "Error(v) = (v - 5)²",
      expression: "Math.pow(x - 5, 2)",
      color: "#FF6B6B"
    },
    {
      name: "Error'(v) = 2(v - 5)",
      expression: "2 * (x - 5)",
      color: "#4ECDC4"
    }
  ])}
/>

## Gradient – Compass in Parameter Space 🧭

### Partial Derivatives

For functions of multiple variables, we compute **partial derivatives** – derivatives with respect to each variable separately.

**Example: Mountain Height Function**
$$
h(x, y) = -(x^2 + y^2)
$$

This is an inverted paraboloid – like a mountain with peak at (0, 0).

Partial derivatives:
$$
\frac{\partial h}{\partial x} = -2x
$$
$$
\frac{\partial h}{\partial y} = -2y
$$

### Gradient – Vector of All Partial Derivatives

**Gradient** is a vector composed of all partial derivatives:

$$
\nabla h = \begin{pmatrix} \frac{\partial h}{\partial x} \\ \frac{\partial h}{\partial y} \end{pmatrix} = \begin{pmatrix} -2x \\ -2y \end{pmatrix}
$$

**Key property:** The gradient points in the direction of steepest increase!

### Gradient Visualization 🏔️

Imagine you're standing on a mountain slope:

```
      Peak (0,0)
         🏔️
        /│\
       / │ \
      /  │  \  ← gradient points up
     /   │   \
    /    │    \
   ──────┴──────
```

**Interactive 3D visualization of the mountain:**

<PlotlyFunction
  type="3d"
  title="Mountain Height Function: h(x,y) = -(x² + y²)"
  xLabel="x"
  yLabel="y"
  zLabel="h(x,y)"
  xRange={[-3, 3]}
  yRange={[-3, 3]}
  functions={JSON.stringify([
    {
      name: "h(x,y) = -(x² + y²)",
      expression: "-(x*x + y*y)",
      colorscale: "Earth"
    }
  ])}
/>

- **Gradient** points in the direction of steepest ascent
- **Negative gradient** points in the direction of steepest descent

**Example calculation:**

At point $(1, 2)$:
$$
\nabla h(1, 2) = \begin{pmatrix} -2 \cdot 1 \\ -2 \cdot 2 \end{pmatrix} = \begin{pmatrix} -2 \\ -4 \end{pmatrix}
$$

This means:
- The function decreases faster in the $y$ direction (component -4)
- To climb the mountain, move in direction $(2, 4)$

## Gradient Descent – AI's Learning Algorithm 🎯

### Basic Idea

**Gradient descent** is a method for finding a function's minimum by moving in the direction opposite to the gradient.

**Algorithm:**
1. Start at a random point
2. Calculate the gradient at this point
3. Take a step in the negative gradient direction
4. Repeat until reaching minimum

### Parameter Update Formula

$$
\theta_{\text{new}} = \theta_{\text{old}} - \alpha \cdot \nabla f(\theta_{\text{old}})
$$

Where:
- $\theta$ – parameters (weights, biases, etc.)
- $\alpha$ – learning rate
- $\nabla f$ – gradient of loss function

### Example: Training the Robot Cat 🤖

Let's return to our cat learning to jump:

**Error function:** $E(v) = (v - 5)^2$

**Derivative:** $E'(v) = 2(v - 5)$

**Training process** with $\alpha = 0.1$:

1. **Attempt 1:** $v_0 = 2$ m/s
   - Error: $E(2) = (2-5)^2 = 9$
   - Gradient: $E'(2) = 2(2-5) = -6$
   - Update: $v_1 = 2 - 0.1 \cdot (-6) = 2.6$

2. **Attempt 2:** $v_1 = 2.6$ m/s
   - Error: $E(2.6) = (2.6-5)^2 = 5.76$
   - Gradient: $E'(2.6) = 2(2.6-5) = -4.8$
   - Update: $v_2 = 2.6 - 0.1 \cdot (-4.8) = 3.08$

3. **Attempt 3:** $v_2 = 3.08$ m/s
   - Error: $E(3.08) = (3.08-5)^2 = 3.69$
   - And so on...

**Progress visualization:**
```
Attempt:   1     2     3     4     5    ...   10
Velocity:  2.0   2.6   3.08  3.46  3.77  ...  4.65
Error:     9.0   5.76  3.69  2.36  1.51  ...  0.12
Cat:       😿    😟    😐    🙂    😊    ...  😸
```

### Choosing the Learning Rate ⚡

The learning rate $\alpha$ is critical:

**Too small** ($\alpha = 0.01$):
```
Iteration: 1    10    50    100   200
Error:     9.0  8.1   5.2   3.3   1.3
           🐌 too slow...
```

**Optimal** ($\alpha = 0.1$):
```
Iteration: 1    5     10    15    20
Error:     9.0  1.5   0.24  0.04  0.006
           ✅ converges quickly!
```

**Too large** ($\alpha = 1.5$):
```
Iteration: 1    2     3     4     5
Error:     9.0  36    144   576   2304
           💥 diverges!
```

## Chain Rule – Foundation of Deep Learning 🔗

### What is the Chain Rule?

**The chain rule** allows us to compute derivatives of composite functions.

If $y = f(g(x))$, then:
$$
\frac{dy}{dx} = \frac{dy}{dg} \cdot \frac{dg}{dx}
$$

### Example: Making the Perfect Pizza 🍕

Imagine the process:
1. **Oven temperature** → **Baking time** → **Pizza quality**

Mathematically:
- $t$ – oven temperature (°C)
- $m = g(t) = \frac{600}{t}$ – baking time (min)
- $q = f(m) = -(m - 15)^2 + 100$ – pizza quality (points)

**Composition:** $q(t) = f(g(t)) = -\left(\frac{600}{t} - 15\right)^2 + 100$

**How does temperature affect quality?**

Using the chain rule:
$$
\frac{dq}{dt} = \frac{dq}{dm} \cdot \frac{dm}{dt}
$$

Calculating:
- $\frac{dq}{dm} = -2(m - 15)$
- $\frac{dm}{dt} = -\frac{600}{t^2}$

Therefore:
$$
\frac{dq}{dt} = -2\left(\frac{600}{t} - 15\right) \cdot \left(-\frac{600}{t^2}\right)
$$

### Application in Neural Networks 🧠

In a neural network, we have many layers:

```
Input → Layer 1 → Layer 2 → ... → Layer N → Output
 x   →  h₁(x)   → h₂(h₁)  → ... → hₙ(...) → y
```

To train the network, we need to know how each weight affects the error. The chain rule allows us to "pass" the gradient backward through all layers!

### Example: Mini-Network for Emotion Recognition 😊😢

**Architecture:**
1. Input: image brightness ($x$)
2. Hidden layer: $h = \text{ReLU}(wx + b)$
3. Output: smile probability $y = \text{sigmoid}(vh + c)$

**Activation functions:**
- ReLU: $\text{ReLU}(z) = \max(0, z)$
- Sigmoid: $\text{sigmoid}(z) = \frac{1}{1 + e^{-z}}$

**Interactive visualization of activation functions:**

<PlotlyFunction
  type="2d"
  title="Common Activation Functions in Neural Networks"
  xLabel="z"
  yLabel="f(z)"
  xRange={[-5, 5]}
  yRange={[-0.5, 5]}
  functions={JSON.stringify([
    {
      name: "ReLU(z) = max(0, z)",
      expression: "Math.max(0, x)",
      color: "#FF6B6B"
    },
    {
      name: "Sigmoid(z) = 1/(1 + e^(-z))",
      expression: "1 / (1 + Math.exp(-x))",
      color: "#4ECDC4"
    },
    {
      name: "Tanh(z)",
      expression: "Math.tanh(x)",
      color: "#45B7D1"
    }
  ])}
/>

**Backpropagation:**

If error $E = (y - y_{\text{target}})^2$, then:

1. Gradient w.r.t. output: $\frac{\partial E}{\partial y} = 2(y - y_{\text{target}})$

2. Gradient w.r.t. $v$ (chain rule):
   $$\frac{\partial E}{\partial v} = \frac{\partial E}{\partial y} \cdot \frac{\partial y}{\partial v} = \frac{\partial E}{\partial y} \cdot y(1-y) \cdot h$$

3. Gradient w.r.t. $w$ (double chain rule):
   $$\frac{\partial E}{\partial w} = \frac{\partial E}{\partial y} \cdot \frac{\partial y}{\partial h} \cdot \frac{\partial h}{\partial w}$$

## Practical Example: Teaching AI to Play Darts 🎯

### Problem Setup

AI controls the force ($f$) and angle ($\theta$) of dart throw. Goal – hit the bullseye.

**Hit function:**
$$
d(f, \theta) = \sqrt{(f\cos\theta - 10)^2 + (f\sin\theta)^2}
$$

Where $d$ – distance from bullseye.

**Loss function:**
$$
L(f, \theta) = d(f, \theta)^2
$$

### Gradient Descent for Two Parameters

**Partial derivatives:**
$$
\frac{\partial L}{\partial f} = 2d \cdot \frac{\partial d}{\partial f}
$$
$$
\frac{\partial L}{\partial \theta} = 2d \cdot \frac{\partial d}{\partial \theta}
$$

**Training process:**

```python
# Initial parameters
f = 5.0      # force
θ = 0.5      # angle (radians)
α = 0.01     # learning rate

# 10 training iterations
for i in range(10):
    # Calculate gradient
    grad_f = calculate_gradient_f(f, θ)
    grad_θ = calculate_gradient_θ(f, θ)
    
    # Update parameters
    f = f - α * grad_f
    θ = θ - α * grad_θ
    
    # Result
    distance = d(f, θ)
    print(f"Attempt {i+1}: distance = {distance:.2f}")
```

**Results visualization:**
```
Attempt 1: 🎯........................ (5.2 cm)
Attempt 3: 🎯.............. (3.1 cm)
Attempt 5: 🎯........ (1.8 cm)
Attempt 7: 🎯.... (0.9 cm)
Attempt 10: 🎯 (0.2 cm) Almost bullseye!
```

## Summary and Key Concepts 🎓

### What We Learned:

1. **Functions** – mathematical rules for transforming data
   - Describe relationships between variables
   - Can have one or many variables

2. **Derivatives** – rate of change of functions
   - Show direction and steepness of change
   - Foundation for optimization

3. **Gradient** – vector of partial derivatives
   - Points in direction of steepest increase
   - Key to learning in multidimensional space

4. **Gradient descent** – optimization algorithm
   - Move against gradient to minimum
   - Learning rate controls step size

5. **Chain rule** – derivatives of composite functions
   - Enables training deep networks
   - Foundation of backpropagation algorithm

### Why This Matters for AI? 🤖

- **Learning = optimization**: AI learns by minimizing a loss function
- **Gradients show direction**: Where to move parameters for improvement
- **Chain rule scales**: Works for networks with millions of parameters
- **Automatic differentiation**: Modern frameworks compute gradients automatically

### Practical Tips 💡

1. **Normalize your data**: Gradients work better with normalized data
2. **Adaptive learning rates**: Use algorithms like Adam
3. **Monitor gradients**: Too small or large gradients are problematic
4. **Regularization**: Add penalties to prevent overfitting

---

**Next lecture:** Activation functions – how to add nonlinearity and teach AI complex relationships! 🚀