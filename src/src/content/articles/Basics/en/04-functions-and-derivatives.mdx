---
title: "Functions and Derivatives - How AI Learns"
description: "What are functions, derivatives, and gradients. How neural networks find optimal solutions through gradient descent"
author: "Department of AIsics"
date: 2024-01-25
readingTime: 25
tags: ["functions", "derivatives", "gradient", "optimization", "learning", "mathematics"]
featured: true
difficulty: "intermediate"
category: "Basics"
prerequisites: ["vectors-in-ai", "matrixes-in-ai"]
relatedArticles: ["matrix-transformations"]
---

import PlotlyFunction from '../../../../components/PlotlyFunction.astro';
import MathPlotSimple from '../../../../components/MathPlotSimple.astro';

# Lecture 4: Functions and Derivatives â€“ How AI Finds the Best Solutions ğŸ“ˆ

In previous lectures, we learned to work with data (vectors and matrices) and transform them. But how does AI know which transformations are needed? How does a neural network "learn" to recognize cats or predict weather? The answer lies in functions and their derivatives!

<div style="background: #fef3c7; border: 2px solid #f59e0b; border-radius: 8px; padding: 1rem; margin: 1rem 0;">
<strong>âš ï¸ Educational Simplification:</strong><br/>
This lecture simplifies mathematical concepts for better understanding. We focus on intuition and practical examples rather than rigorous proofs. Visualizations may be schematic for clarity.
</div>

## Functions â€“ Mathematical "Transformers" ğŸ”„

### What is a Function?

**A function** is a rule that assigns exactly one output value to each input value (or set of values).

Think of a function as a **machine** that:
- ğŸ“¥ Takes input data
- âš™ï¸ Processes it according to a rule
- ğŸ“¤ Produces a result

### Example 1: Coffee Machine â˜•

Imagine a function "making coffee":

$$
f(\text{coffee\_amount}) = \text{drink\_strength}
$$

More specifically:
$$
f(x) = 2x + 1
$$

Where:
- $x$ â€“ grams of coffee
- $f(x)$ â€“ drink strength (arbitrary units)

**Calculations:**
- $f(5) = 2 \cdot 5 + 1 = 11$ (5g coffee â†’ strength 11)
- $f(10) = 2 \cdot 10 + 1 = 21$ (10g coffee â†’ strength 21)
- $f(15) = 2 \cdot 15 + 1 = 31$ (15g coffee â†’ strength 31)

**Interactive visualization:**

<MathPlotSimple
  expression="2 * x + 1"
  name="f(x) = 2x + 1"
  title="Coffee Strength Function"
  xRange={[0, 20]}
  yRange={[0, 45]}
  color="#8B4513"
/>

### Example 2: Robot Cat's Error Function ğŸ¤–ğŸ±

Our robot cat is trying to jump onto a shelf. The error function:

$$
\text{Error}(v) = (v - 5)^2
$$

Where:
- $v$ â€“ jump velocity (m/s)
- 5 m/s â€“ ideal velocity
- Error â€“ how far from the target the cat landed

**Error visualization:**
```
Velocity:   3    4    5    6    7
Error:      4    1    0    1    4
            ğŸ˜¿   ğŸ˜   ğŸ˜¸   ğŸ˜   ğŸ˜¿
```

We see that:
- At $v = 5$: error = 0 (perfect! ğŸ˜¸)
- At $v < 5$: undershoot (ğŸ˜¿)
- At $v > 5$: overshoot (ğŸ˜¿)

**Interactive error function:**

<MathPlotSimple
  expression="Math.pow(x - 5, 2)"
  name="Error(v) = (v - 5)Â²"
  title="Robot Cat's Jump Error Function"
  xRange={[0, 10]}
  yRange={[0, 30]}
  color="#FF6B6B"
/>

### Functions of Multiple Variables ğŸ“Š

In real AI, functions depend on many parameters.

**Example: Apartment Price**

$$
\text{Price} = f(\text{area}, \text{rooms}, \text{floor}, \text{district})
$$

Simplified model:
$$
f(x_1, x_2, x_3) = 1000x_1 + 50000x_2 - 5000x_3 + 200000
$$

Where:
- $x_1$ â€“ area (mÂ²)
- $x_2$ â€“ number of rooms
- $x_3$ â€“ floor
- 200000 â€“ base price

**Sample calculation:**
- Area: 60 mÂ²
- Rooms: 2
- Floor: 5

$$
f(60, 2, 5) = 1000 \cdot 60 + 50000 \cdot 2 - 5000 \cdot 5 + 200000
$$
$$
= 60000 + 100000 - 25000 + 200000 = 335000 \text{ USD}
$$

## Derivatives â€“ Rate of Change ğŸƒâ€â™‚ï¸

### Intuitive Understanding

**The derivative** shows how quickly a function changes as its input changes.

### Example: Car Speed ğŸš—

If a car's position is described by the function:
$$
s(t) = 5t^2
$$

Where $s$ â€“ distance (m), $t$ â€“ time (s).

**Speed** is the derivative of position with respect to time:
$$
v(t) = s'(t) = 10t
$$

**What this means:**
- At time $t = 1$: speed = 10 m/s
- At time $t = 2$: speed = 20 m/s
- At time $t = 3$: speed = 30 m/s

The car is accelerating!

### Geometric Meaning of Derivative ğŸ“

The derivative at a point = slope of the tangent line to the function graph at that point.

**Visualization for** $f(x) = x^2$:

```
      |     .
      |   .   (slope = 4)
  f(x)|  .
      | . (slope = 2)
      |. (slope = 0)
      +------------- x
```

- At point $x = 0$: $f'(0) = 0$ (horizontal tangent)
- At point $x = 1$: $f'(1) = 2$ (tangent goes up)
- At point $x = 2$: $f'(2) = 4$ (tangent goes up steeper)

**Interactive visualization of f(x) = xÂ² and its derivative:**

<PlotlyFunction
  type="2d"
  title="Function f(x) = xÂ² and its Derivative f'(x) = 2x"
  xLabel="x"
  yLabel="y"
  xRange={[-3, 3]}
  yRange={[-2, 10]}
  functions={JSON.stringify([
    {
      name: "f(x) = xÂ²",
      expression: "x * x",
      color: "#3498DB"
    },
    {
      name: "f'(x) = 2x",
      expression: "2 * x",
      color: "#E74C3C"
    }
  ])}
/>

### Differentiation Rules ğŸ“

**Basic rules:**

1. **Constant:** $\frac{d}{dx}(c) = 0$
2. **Power function:** $\frac{d}{dx}(x^n) = nx^{n-1}$
3. **Sum:** $\frac{d}{dx}[f(x) + g(x)] = f'(x) + g'(x)$
4. **Constant multiple:** $\frac{d}{dx}[c \cdot f(x)] = c \cdot f'(x)$

**Example application:**

For the cat's error function:
$$
\text{Error}(v) = (v - 5)^2 = v^2 - 10v + 25
$$

Derivative:
$$
\text{Error}'(v) = 2v - 10
$$

**What this means:**
- When $v < 5$: derivative is negative â†’ error decreases as velocity increases
- When $v > 5$: derivative is positive â†’ error increases as velocity increases
- When $v = 5$: derivative = 0 â†’ minimum error!

**Visualizing the error function and its derivative:**

<PlotlyFunction
  type="2d"
  title="Error Function and Its Derivative"
  xLabel="Velocity (m/s)"
  yLabel="Value"
  xRange={[0, 10]}
  yRange={[-15, 30]}
  functions={JSON.stringify([
    {
      name: "Error(v) = (v - 5)Â²",
      expression: "Math.pow(x - 5, 2)",
      color: "#FF6B6B"
    },
    {
      name: "Error'(v) = 2(v - 5)",
      expression: "2 * (x - 5)",
      color: "#4ECDC4"
    }
  ])}
/>

## Gradient â€“ Compass in Parameter Space ğŸ§­

### Partial Derivatives

For functions of multiple variables, we compute **partial derivatives** â€“ derivatives with respect to each variable separately.

**Example: Mountain Height Function**
$$
h(x, y) = -(x^2 + y^2)
$$

This is an inverted paraboloid â€“ like a mountain with peak at (0, 0).

Partial derivatives:
$$
\frac{\partial h}{\partial x} = -2x
$$
$$
\frac{\partial h}{\partial y} = -2y
$$

### Gradient â€“ Vector of All Partial Derivatives

**Gradient** is a vector composed of all partial derivatives:

$$
\nabla h = \begin{pmatrix} \frac{\partial h}{\partial x} \\ \frac{\partial h}{\partial y} \end{pmatrix} = \begin{pmatrix} -2x \\ -2y \end{pmatrix}
$$

**Key property:** The gradient points in the direction of steepest increase!

### Gradient Visualization ğŸ”ï¸

Imagine you're standing on a mountain slope:

```
      Peak (0,0)
         ğŸ”ï¸
        /â”‚\
       / â”‚ \
      /  â”‚  \  â† gradient points up
     /   â”‚   \
    /    â”‚    \
   â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€
```

**Interactive 3D visualization of the mountain:**

<PlotlyFunction
  type="3d"
  title="Mountain Height Function: h(x,y) = -(xÂ² + yÂ²)"
  xLabel="x"
  yLabel="y"
  zLabel="h(x,y)"
  xRange={[-3, 3]}
  yRange={[-3, 3]}
  functions={JSON.stringify([
    {
      name: "h(x,y) = -(xÂ² + yÂ²)",
      expression: "-(x*x + y*y)",
      colorscale: "Earth"
    }
  ])}
/>

- **Gradient** points in the direction of steepest ascent
- **Negative gradient** points in the direction of steepest descent

**Example calculation:**

At point $(1, 2)$:
$$
\nabla h(1, 2) = \begin{pmatrix} -2 \cdot 1 \\ -2 \cdot 2 \end{pmatrix} = \begin{pmatrix} -2 \\ -4 \end{pmatrix}
$$

This means:
- The function decreases faster in the $y$ direction (component -4)
- To climb the mountain, move in direction $(2, 4)$

## Gradient Descent â€“ AI's Learning Algorithm ğŸ¯

### Basic Idea

**Gradient descent** is a method for finding a function's minimum by moving in the direction opposite to the gradient.

**Algorithm:**
1. Start at a random point
2. Calculate the gradient at this point
3. Take a step in the negative gradient direction
4. Repeat until reaching minimum

### Parameter Update Formula

$$
\theta_{\text{new}} = \theta_{\text{old}} - \alpha \cdot \nabla f(\theta_{\text{old}})
$$

Where:
- $\theta$ â€“ parameters (weights, biases, etc.)
- $\alpha$ â€“ learning rate
- $\nabla f$ â€“ gradient of loss function

### Example: Training the Robot Cat ğŸ¤–

Let's return to our cat learning to jump:

**Error function:** $E(v) = (v - 5)^2$

**Derivative:** $E'(v) = 2(v - 5)$

**Training process** with $\alpha = 0.1$:

1. **Attempt 1:** $v_0 = 2$ m/s
   - Error: $E(2) = (2-5)^2 = 9$
   - Gradient: $E'(2) = 2(2-5) = -6$
   - Update: $v_1 = 2 - 0.1 \cdot (-6) = 2.6$

2. **Attempt 2:** $v_1 = 2.6$ m/s
   - Error: $E(2.6) = (2.6-5)^2 = 5.76$
   - Gradient: $E'(2.6) = 2(2.6-5) = -4.8$
   - Update: $v_2 = 2.6 - 0.1 \cdot (-4.8) = 3.08$

3. **Attempt 3:** $v_2 = 3.08$ m/s
   - Error: $E(3.08) = (3.08-5)^2 = 3.69$
   - And so on...

**Progress visualization:**
```
Attempt:   1     2     3     4     5    ...   10
Velocity:  2.0   2.6   3.08  3.46  3.77  ...  4.65
Error:     9.0   5.76  3.69  2.36  1.51  ...  0.12
Cat:       ğŸ˜¿    ğŸ˜Ÿ    ğŸ˜    ğŸ™‚    ğŸ˜Š    ...  ğŸ˜¸
```

### Choosing the Learning Rate âš¡

The learning rate $\alpha$ is critical:

**Too small** ($\alpha = 0.01$):
```
Iteration: 1    10    50    100   200
Error:     9.0  8.1   5.2   3.3   1.3
           ğŸŒ too slow...
```

**Optimal** ($\alpha = 0.1$):
```
Iteration: 1    5     10    15    20
Error:     9.0  1.5   0.24  0.04  0.006
           âœ… converges quickly!
```

**Too large** ($\alpha = 1.5$):
```
Iteration: 1    2     3     4     5
Error:     9.0  36    144   576   2304
           ğŸ’¥ diverges!
```

## Chain Rule â€“ Foundation of Deep Learning ğŸ”—

### What is the Chain Rule?

**The chain rule** allows us to compute derivatives of composite functions.

If $y = f(g(x))$, then:
$$
\frac{dy}{dx} = \frac{dy}{dg} \cdot \frac{dg}{dx}
$$

### Example: Making the Perfect Pizza ğŸ•

Imagine the process:
1. **Oven temperature** â†’ **Baking time** â†’ **Pizza quality**

Mathematically:
- $t$ â€“ oven temperature (Â°C)
- $m = g(t) = \frac{600}{t}$ â€“ baking time (min)
- $q = f(m) = -(m - 15)^2 + 100$ â€“ pizza quality (points)

**Composition:** $q(t) = f(g(t)) = -\left(\frac{600}{t} - 15\right)^2 + 100$

**How does temperature affect quality?**

Using the chain rule:
$$
\frac{dq}{dt} = \frac{dq}{dm} \cdot \frac{dm}{dt}
$$

Calculating:
- $\frac{dq}{dm} = -2(m - 15)$
- $\frac{dm}{dt} = -\frac{600}{t^2}$

Therefore:
$$
\frac{dq}{dt} = -2\left(\frac{600}{t} - 15\right) \cdot \left(-\frac{600}{t^2}\right)
$$

### Application in Neural Networks ğŸ§ 

In a neural network, we have many layers:

```
Input â†’ Layer 1 â†’ Layer 2 â†’ ... â†’ Layer N â†’ Output
 x   â†’  hâ‚(x)   â†’ hâ‚‚(hâ‚)  â†’ ... â†’ hâ‚™(...) â†’ y
```

To train the network, we need to know how each weight affects the error. The chain rule allows us to "pass" the gradient backward through all layers!

### Example: Mini-Network for Emotion Recognition ğŸ˜ŠğŸ˜¢

**Architecture:**
1. Input: image brightness ($x$)
2. Hidden layer: $h = \text{ReLU}(wx + b)$
3. Output: smile probability $y = \text{sigmoid}(vh + c)$

**Activation functions:**
- ReLU: $\text{ReLU}(z) = \max(0, z)$
- Sigmoid: $\text{sigmoid}(z) = \frac{1}{1 + e^{-z}}$

**Interactive visualization of activation functions:**

<PlotlyFunction
  type="2d"
  title="Common Activation Functions in Neural Networks"
  xLabel="z"
  yLabel="f(z)"
  xRange={[-5, 5]}
  yRange={[-0.5, 5]}
  functions={JSON.stringify([
    {
      name: "ReLU(z) = max(0, z)",
      expression: "Math.max(0, x)",
      color: "#FF6B6B"
    },
    {
      name: "Sigmoid(z) = 1/(1 + e^(-z))",
      expression: "1 / (1 + Math.exp(-x))",
      color: "#4ECDC4"
    },
    {
      name: "Tanh(z)",
      expression: "Math.tanh(x)",
      color: "#45B7D1"
    }
  ])}
/>

**Backpropagation:**

If error $E = (y - y_{\text{target}})^2$, then:

1. Gradient w.r.t. output: $\frac{\partial E}{\partial y} = 2(y - y_{\text{target}})$

2. Gradient w.r.t. $v$ (chain rule):
   $$\frac{\partial E}{\partial v} = \frac{\partial E}{\partial y} \cdot \frac{\partial y}{\partial v} = \frac{\partial E}{\partial y} \cdot y(1-y) \cdot h$$

3. Gradient w.r.t. $w$ (double chain rule):
   $$\frac{\partial E}{\partial w} = \frac{\partial E}{\partial y} \cdot \frac{\partial y}{\partial h} \cdot \frac{\partial h}{\partial w}$$

## Practical Example: Teaching AI to Play Darts ğŸ¯

### Problem Setup

AI controls the force ($f$) and angle ($\theta$) of dart throw. Goal â€“ hit the bullseye.

**Hit function:**
$$
d(f, \theta) = \sqrt{(f\cos\theta - 10)^2 + (f\sin\theta)^2}
$$

Where $d$ â€“ distance from bullseye.

**Loss function:**
$$
L(f, \theta) = d(f, \theta)^2
$$

### Gradient Descent for Two Parameters

**Partial derivatives:**
$$
\frac{\partial L}{\partial f} = 2d \cdot \frac{\partial d}{\partial f}
$$
$$
\frac{\partial L}{\partial \theta} = 2d \cdot \frac{\partial d}{\partial \theta}
$$

**Training process:**

```python
# Initial parameters
f = 5.0      # force
Î¸ = 0.5      # angle (radians)
Î± = 0.01     # learning rate

# 10 training iterations
for i in range(10):
    # Calculate gradient
    grad_f = calculate_gradient_f(f, Î¸)
    grad_Î¸ = calculate_gradient_Î¸(f, Î¸)
    
    # Update parameters
    f = f - Î± * grad_f
    Î¸ = Î¸ - Î± * grad_Î¸
    
    # Result
    distance = d(f, Î¸)
    print(f"Attempt {i+1}: distance = {distance:.2f}")
```

**Results visualization:**
```
Attempt 1: ğŸ¯........................ (5.2 cm)
Attempt 3: ğŸ¯.............. (3.1 cm)
Attempt 5: ğŸ¯........ (1.8 cm)
Attempt 7: ğŸ¯.... (0.9 cm)
Attempt 10: ğŸ¯ (0.2 cm) Almost bullseye!
```

## Summary and Key Concepts ğŸ“

### What We Learned:

1. **Functions** â€“ mathematical rules for transforming data
   - Describe relationships between variables
   - Can have one or many variables

2. **Derivatives** â€“ rate of change of functions
   - Show direction and steepness of change
   - Foundation for optimization

3. **Gradient** â€“ vector of partial derivatives
   - Points in direction of steepest increase
   - Key to learning in multidimensional space

4. **Gradient descent** â€“ optimization algorithm
   - Move against gradient to minimum
   - Learning rate controls step size

5. **Chain rule** â€“ derivatives of composite functions
   - Enables training deep networks
   - Foundation of backpropagation algorithm

### Why This Matters for AI? ğŸ¤–

- **Learning = optimization**: AI learns by minimizing a loss function
- **Gradients show direction**: Where to move parameters for improvement
- **Chain rule scales**: Works for networks with millions of parameters
- **Automatic differentiation**: Modern frameworks compute gradients automatically

### Practical Tips ğŸ’¡

1. **Normalize your data**: Gradients work better with normalized data
2. **Adaptive learning rates**: Use algorithms like Adam
3. **Monitor gradients**: Too small or large gradients are problematic
4. **Regularization**: Add penalties to prevent overfitting

---

**Next lecture:** Activation functions â€“ how to add nonlinearity and teach AI complex relationships! ğŸš€